{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from neurorag.neurorag import NeuroRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment variables\n",
    "\n",
    "You have to define the following environment variables in the `.env` file, terminal environment, or input field within this Jupyter notebook:\n",
    "1. MISTRAL_API_KEY\n",
    "2. OPENAI_API_KEY\n",
    "3. OPENAI_PROXY\n",
    "4. TAVILY_API_KEY\n",
    "5. ENTREZ_EMAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables = [\n",
    "  'MISTRAL_API_KEY',\n",
    "  'OPENAI_API_KEY',\n",
    "  'OPENAI_PROXY',\n",
    "  'TAVILY_API_KEY',\n",
    "  'ENTREZ_EMAIL',\n",
    "]\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for key in env_variables:\n",
    "  value = os.getenv(key)\n",
    "\n",
    "  if value is None:\n",
    "    value = getpass(key)\n",
    "\n",
    "  os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MMLU tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response):\n",
    "  json_pattern = r'\\{.*?\\}'\n",
    "  match = re.search(json_pattern, response, re.DOTALL)\n",
    "\n",
    "  if match:\n",
    "    return match.group().strip().replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSchema(BaseModel):\n",
    "  correct_answer: str = Field(description='Given a question and answer options, provide the corresponding letter for the correct answer.')\n",
    "\n",
    "rag_parser = PydanticOutputParser(pydantic_object=RAGSchema)\n",
    "\n",
    "rag_template = \"\"\"Answer the following multiple choice question by giving the most appropriate response in json format. Answer should be one among [A, B, C, D].\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Question: {question}\\n\n",
    "A) {a}\\n\n",
    "B) {b}\\n\n",
    "C) {c}\\n\n",
    "D) {d}\\n\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "  template=rag_template,\n",
    "  input_variables=['question', 'a', 'b', 'c', 'd', 'context'],\n",
    "  partial_variables={'format_instructions': rag_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "letter_to_number = {'a': 0, 'b': 1, 'c': 2, 'd': 3}\n",
    "\n",
    "def eval_rag(app, mmlu_subset: str) -> float:\n",
    "  dataset = load_dataset('cais/mmlu', mmlu_subset)\n",
    "  test_df = dataset['test'].to_pandas()\n",
    "\n",
    "  correct_answers_count = 0\n",
    "\n",
    "  for index, row in tqdm(list(test_df.iterrows()), desc='Questions'):\n",
    "    question = row['question']\n",
    "    choices = row['choices']\n",
    "    correct_answer = row['answer']\n",
    "\n",
    "    while True:\n",
    "      try:\n",
    "        prompt_with_choices = prompt.partial(\n",
    "          a=choices[0],\n",
    "          b=choices[1],\n",
    "          c=choices[2],\n",
    "          d=choices[3],\n",
    "        )\n",
    "        llm_answer = app.invoke(question, prompt_with_choices)\n",
    "        break\n",
    "      except Exception as e:\n",
    "        print(index, e)\n",
    "        pass\n",
    "\n",
    "    json_string = extract_json(llm_answer['generation'])\n",
    "    response_object = rag_parser.invoke(json_string)\n",
    "\n",
    "    llm_answer_letter = response_object.correct_answer.strip().lower()[0]\n",
    "\n",
    "    if llm_answer_letter not in letter_to_number:\n",
    "      continue\n",
    "\n",
    "    llm_answer_num = letter_to_number[llm_answer_letter]\n",
    "\n",
    "    if llm_answer_num == correct_answer:\n",
    "      correct_answers_count += 1\n",
    "\n",
    "  return correct_answers_count / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = NeuroRAG()\n",
    "app.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets: list[str] = [\n",
    "  'medical_genetics',\n",
    "  'college_biology',\n",
    "  'college_medicine',\n",
    "]\n",
    "\n",
    "for subset in subsets:\n",
    "  print(f'{subset}: {eval_rag(app, subset)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
