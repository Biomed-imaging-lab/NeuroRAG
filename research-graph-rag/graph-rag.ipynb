{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet nltk numpy pandas unidecode scikit-learn tqdm llm-blender rouge-score xmltodict arxiv biopython rank_bm25\n",
    "! pip install --quiet langchain langchain-core langchain-community langchain_experimental langchain-openai langchain-chroma langchain_mistralai langgraph langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import llm_blender\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from Bio import Entrez, SeqIO\n",
    "import torch\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings.cache import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import RetryOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.retrievers import PubMedRetriever, ArxivRetriever, BM25Retriever\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment variables\n",
    "\n",
    "You have to define the following environment variables in the `.env` file, terminal environment, or input field within this Jupyter notebook:\n",
    "1. MISTRAL_API_KEY\n",
    "2. OPENAI_API_KEY\n",
    "3. OPENAI_PROXY\n",
    "4. TAVILY_API_KEY\n",
    "5. ENTREZ_EMAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables = [\n",
    "  'MISTRAL_API_KEY',\n",
    "  'OPENAI_API_KEY',\n",
    "  'OPENAI_PROXY',\n",
    "  'TAVILY_API_KEY',\n",
    "  'ENTREZ_EMAIL',\n",
    "]\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for key in env_variables:\n",
    "  value = os.getenv(key)\n",
    "\n",
    "  if value is None:\n",
    "    value = getpass(key)\n",
    "\n",
    "  os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NLTK dictionaries\n",
    "\n",
    "These dictionaries are needed for further text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ids = [\n",
    "  'punkt_tab',\n",
    "  'punkt',\n",
    "  'stopwords',\n",
    "  'wordnet',\n",
    "]\n",
    "\n",
    "for dict_id in dict_ids:\n",
    "  nltk.download(dict_id, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Define a function for text preprocessing, which is an important step before calculating any metrics. This preprocessing function will help in cleaning the text data, making it ready for further analysis. The preprocessing involves several steps:\n",
    "1. Lowercasing\n",
    "2. Stopwords removal\n",
    "3. Lemmatization\n",
    "4. Remove accents from characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess(corpus: str) -> str:\n",
    "  corpus = corpus.lower()\n",
    "  stopset = nltk.corpus.stopwords.words('english') + nltk.corpus.stopwords.words('russian') + list(string.punctuation)\n",
    "  tokens = nltk.word_tokenize(corpus)\n",
    "  tokens = [t for t in tokens if t not in stopset]\n",
    "  tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "  corpus = ' '.join(tokens)\n",
    "  corpus = unidecode(corpus)\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Initialization\n",
    "\n",
    "Here we are initializing the Llama 3 embeddings model. The `OllamaEmbeddings` class is a component of the Ollama library, a set of pre-trained language models. This model is capable of embedding corpora of any length into a 4096-dimensional vector.\n",
    "\n",
    "The use of `OllamaEmbeddings` requires the installation of a local Ollama server, which can be found at https://ollama.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model='llama3.1')\n",
    "store = LocalFileStore(\"./.embeddings_cache\")\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "  embeddings,\n",
    "  store,\n",
    "  namespace=embeddings.model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average embeddings cosine similarity metric\n",
    "\n",
    "This function calculates the average cosine similarity between expected answers and LLM predicted answers using their respective embeddings. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them:\n",
    "\n",
    "$$\n",
    "K(a, b) = \\frac{\\sum \\limits_{i=1}^n a_i b_i}{\\sqrt{\\sum \\limits_{i=1}^n a_i^2} \\cdot \\sqrt{\\sum \\limits_{i=1}^n b_i^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_cosine_sim_metric(expected_answers: list[str], predicted_answers: list[str]) -> float:\n",
    "  results = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    expected_embedding = np.array(cached_embeddings.embed_query(expected_answer))\n",
    "    predicted_embedding = np.array(cached_embeddings.embed_query(predicted_answer))\n",
    "\n",
    "    sim = cosine_similarity(\n",
    "      expected_embedding.reshape(1, -1),\n",
    "      predicted_embedding.reshape(1, -1),\n",
    "    )[0][0]\n",
    "\n",
    "    results.append(sim)\n",
    "\n",
    "  return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothie_f = nltk.translate.bleu_score.SmoothingFunction().method4\n",
    "\n",
    "def bleu_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    predicted_tokens = nltk.word_tokenize(predicted_answer)\n",
    "    expected_tokens = [nltk.word_tokenize(expected_answer)]\n",
    "\n",
    "    score = nltk.translate.bleu_score.sentence_bleu(\n",
    "      expected_tokens,\n",
    "      predicted_tokens,\n",
    "      smoothing_function=smoothie_f,\n",
    "    )\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogue_1_scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "def rogue_1_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    result = rogue_1_scorer.score(expected_answer, predicted_answer)\n",
    "\n",
    "    scores.append(result['rouge1'])\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogue_l_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def rogue_l_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    result = rogue_l_scorer.score(expected_answer, predicted_answer)\n",
    "\n",
    "    scores.append(result['rougeL'])\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4438"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_dir = Path('./docs')\n",
    "docs_cache_dir = Path('./.docs_cache')\n",
    "raw_docs_pkl_path = docs_cache_dir / 'parsed_docs_cache.pkl'\n",
    "\n",
    "if os.path.exists(raw_docs_pkl_path):\n",
    "  with open(raw_docs_pkl_path, 'rb') as f:\n",
    "    docs = pickle.load(f)\n",
    "else:\n",
    "  docs = []\n",
    "\n",
    "  for file in docs_dir.iterdir():\n",
    "    file_docs = PDFMinerLoader(file, concatenate_pages=False).load()\n",
    "    for doc in file_docs:\n",
    "      doc.page_content = unidecode(doc.page_content)\n",
    "      page = doc.metadata['page']\n",
    "      doc.metadata['source'] = f'{file.stem} ({page})'\n",
    "    docs.extend(file_docs)\n",
    "\n",
    "  with open(raw_docs_pkl_path, 'wb') as f:\n",
    "    pickle.dump(docs, f)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35663"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_docs_pkl_path = docs_cache_dir / 'splitted_docs_cache.pkl'\n",
    "\n",
    "if os.path.exists(splitted_docs_pkl_path):\n",
    "  with open(splitted_docs_pkl_path, 'rb') as f:\n",
    "    splitted_docs = pickle.load(f)\n",
    "else:\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=750,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    separators=[\n",
    "      '.',\n",
    "      '\\uff0e', # Fullwidth full stop\n",
    "      '\\u3002', # Ideographic full stop\n",
    "      '\\n\\n',\n",
    "    ],\n",
    "  )\n",
    "  splitted_docs = text_splitter.create_documents([doc.page_content for doc in docs])\n",
    "\n",
    "  with open(splitted_docs_pkl_path, 'wb') as f:\n",
    "    pickle.dump(splitted_docs, f)\n",
    "\n",
    "len(splitted_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "  collection_name='neurorag',\n",
    "  embedding_function=cached_embeddings,\n",
    "  persist_directory='./chroma_db'\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define JSON extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response):\n",
    "  json_pattern = r'\\{.*?\\}'\n",
    "  match = re.search(json_pattern, response, re.DOTALL)\n",
    "\n",
    "  if match:\n",
    "    return match.group().strip().replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model='llama3.1', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sources=[]\n",
      "sources=['vectorstore', 'ncbi_gene']\n"
     ]
    }
   ],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "  sources: List[str] = Field(\n",
    "    description='Given a user question select the retrieval methods you consider the most appropriate for addressing this question. You may also return an empty array if no methods are required.',\n",
    "  )\n",
    "\n",
    "route_parser = PydanticOutputParser(pydantic_object=RouteQuery)\n",
    "route_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=route_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "route_template = \"\"\"\n",
    "You are an expert at selecting retrieval methods.\n",
    "Given a user question select the retrieval methods you consider the most appropriate for addressing user question.\n",
    "You may also return an empty array if no methods are required.\n",
    "\n",
    "Possible retrieval methods:\n",
    "1. The \"vectorstore\" retriever contains documents related to neurobiology and medicine. Use the vectorstore for questions on these topics.\n",
    "2. The \"pubmed\" retriever contains biomedical literature and research articles. It is particularly useful for answering detailed questions about medical research, clinical studies, and scientific discoveries.\n",
    "3. The \"arxiv\" retriever contains preprints of research papers across various scientific fields, including physics, mathematics, computer science, and biology. Use the arxiv for questions on recent scientific research and theoretical studies in these areas.\n",
    "4. The \"ncbi_protein\" retriever contains protein sequence and functional information. Use the NCBI protein DB for questions related to protein sequences, structures, and functions.\n",
    "5. The \"ncbi_gene\" retriever contains gene sequence and functional information. Use the NCBI gene DB for questions related to gene sequences, structures, and functions.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\"\"\"\n",
    "route_prompt = PromptTemplate(\n",
    "  template=route_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': route_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "question_router = RunnableParallel(\n",
    "  completion=route_prompt | llm | extract_json, prompt_value=route_prompt\n",
    ") | RunnableLambda(lambda x: route_retry_parser.parse_with_prompt(**x))\n",
    "print(question_router.invoke({'question': 'Who will the Bears draft first in the NFL draft?'}))\n",
    "print(question_router.invoke({'question': 'What are the functions of the oculomotor nerve?'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade documents chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeDocuments(binary_score='yes')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "  binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "docs_grader_parser = PydanticOutputParser(pydantic_object=GradeDocuments)\n",
    "docs_grader_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=docs_grader_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "docs_grader_template = \"\"\"\n",
    "You are a grader assessing relevance of a retrieved document to a user question.\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Retrieved document:\n",
    "{document}\n",
    "\"\"\"\n",
    "docs_grader_prompt = PromptTemplate(\n",
    "  template=docs_grader_template,\n",
    "  input_variables=['document', 'question'],\n",
    "  partial_variables={'format_instructions': docs_grader_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "docs_grader_chain = RunnableParallel(\n",
    "  completion=docs_grader_prompt | llm | extract_json, prompt_value=docs_grader_prompt\n",
    ") | RunnableLambda(lambda x: docs_grader_retry_parser.parse_with_prompt(**x))\n",
    "docs_grader_chain.invoke({'question': 'What is the color of the sky?', 'document': 'The color of the sky is blue'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucinations chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "  binary_score: str = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
    "\n",
    "hallucination_parser = PydanticOutputParser(pydantic_object=GradeHallucinations)\n",
    "hallucination_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=hallucination_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "hallucination_template = \"\"\"\n",
    "You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Set of facts:\n",
    "{documents}\n",
    "\n",
    "LLM generation:\n",
    "{generation}\n",
    "\"\"\"\n",
    "hallucination_prompt = PromptTemplate(\n",
    "  template=hallucination_template,\n",
    "  input_variables=['question', 'generation'],\n",
    "  partial_variables={'format_instructions': hallucination_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "hallucination_grader = RunnableParallel(\n",
    "  completion=hallucination_prompt | llm | extract_json, prompt_value=hallucination_prompt\n",
    ") | RunnableLambda(lambda x: hallucination_retry_parser.parse_with_prompt(**x))\n",
    "print(hallucination_grader.invoke({'documents': ['Sky is blue'], 'generation': 'The color of the sky is blue'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer grade chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "  binary_score: str = Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "\n",
    "grade_parser = PydanticOutputParser(pydantic_object=GradeAnswer)\n",
    "grade_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=grade_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "grade_template = \"\"\"\n",
    "You are a grader assessing whether an answer addresses / resolves a question. \\n\n",
    "Give a binary score 'yes' or 'no'. 'yes' means that the answer resolves the question.\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "LLM generation:\n",
    "{generation}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "grade_prompt = PromptTemplate(\n",
    "  template=grade_template,\n",
    "  input_variables=['question', 'generation'],\n",
    "  partial_variables={'format_instructions': grade_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "answer_grader = RunnableParallel(\n",
    "  completion=grade_prompt | llm | extract_json, prompt_value=grade_prompt\n",
    ") | RunnableLambda(lambda x: grade_retry_parser.parse_with_prompt(**x))\n",
    "print(answer_grader.invoke({\"question\": \"What is the order of the cranial nerves?\", 'generation': 'I do not know.'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a scientific paper-style passage answering the question:\\n\\n**Title:** The Cranial Nerve Order: A Review and Classification\\n\\n**Abstract:**\\n\\nThe cranial nerves are a complex group of 12 pairs of nerves that arise directly from the brain, playing crucial roles in various physiological functions. Despite their importance, the order of these nerves has been a subject of interest for centuries. This review aims to provide an overview of the classification and nomenclature of the cranial nerves, highlighting their distinct characteristics and functions.\\n\\n**Introduction:**\\n\\nThe cranial nerves are a unique group of nerves that emerge from the brain, serving as the primary means of communication between the central nervous system and various peripheral structures. The order of these nerves has been a topic of debate among neuroscientists, with different classification systems proposed over the years. In this review, we will present an updated classification scheme for the cranial nerves, highlighting their distinct characteristics and functions.\\n\\n**The Order of the Cranial Nerves:**\\n\\nThe 12 pairs of cranial nerves are traditionally listed in the following order:\\n\\n1. **Olfactory nerve (I)**: The first cranial nerve to develop, responsible for transmitting sensory information from the olfactory epithelium.\\n2. **Optic nerve (II)**: A paired nerve that transmits visual information from the retina to the brain.\\n3. **Occulomotor nerve (III)**: A large motor nerve that controls eye movement and pupillary constriction.\\n4. **Trochlear nerve (IV)**: The thinnest cranial nerve, responsible for controlling superior oblique muscle function.\\n5. **Trigeminal nerve (V)**: A complex nerve with three branches (ophthalmic, maxillary, and mandibular) that transmit sensory information from the face and motor signals to the muscles of mastication.\\n6. **Abducens nerve (VI)**: A small motor nerve that controls lateral rectus muscle function.\\n7. **Facial nerve (VII)**: A mixed nerve responsible for transmitting taste, smell, and auditory information, as well as controlling facial expressions and salivation.\\n8. **Vestibulocochlear nerve (VIII)**: A paired nerve that transmits auditory and vestibular information from the inner ear to the brain.\\n9. **Glossopharyngeal nerve (IX)**: A mixed nerve responsible for transmitting sensory information from the pharynx, tongue, and ear, as well as controlling swallowing and salivation.\\n10. **Vagus nerve (X)**: A complex nerve with multiple branches that transmit sensory information from various organs and control various physiological functions, including respiration and digestion.\\n11. **Spinal accessory nerve (XI)**: A motor nerve responsible for controlling sternocleidomastoid and trapezius muscle function.\\n12. **Hypoglossal nerve (XII)**: The smallest cranial nerve, responsible for controlling tongue movement.\\n\\n**Conclusion:**\\n\\nIn conclusion, the order of the cranial nerves is a well-established classification scheme that has been refined over centuries. Understanding the distinct characteristics and functions of each nerve pair is essential for appreciating their roles in various physiological processes. This review aims to provide a comprehensive overview of the cranial nerve order, highlighting their importance in human anatomy and physiology.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_template = \"\"\"\n",
    "Please write a scientific paper passage to answer the question\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Passage:\n",
    "\"\"\"\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_template)\n",
    "hyde_chain = hyde_prompt | llm | StrOutputParser()\n",
    "\n",
    "hyde_chain.invoke({\"question\": 'What is the order of the cranial nerves ?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_back='What are rare genetic disorders that affect the nervous system?'\n"
     ]
    }
   ],
   "source": [
    "class StepBackAnswer(BaseModel):\n",
    "  step_back: str = Field(description=\"Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\")\n",
    "\n",
    "\n",
    "step_back_parser = PydanticOutputParser(pydantic_object=StepBackAnswer)\n",
    "step_back_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=step_back_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "step_back_template = \"\"\"\n",
    "You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "Step-back query:\n",
    "\"\"\"\n",
    "step_back_prompt = PromptTemplate(\n",
    "  template=step_back_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': step_back_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "step_back_chain = RunnableParallel(\n",
    "  completion=step_back_prompt | llm | extract_json, prompt_value=step_back_prompt\n",
    ") | RunnableLambda(lambda x: step_back_retry_parser.parse_with_prompt(**x))\n",
    "print(step_back_chain.invoke({\"question\": \"What is Benedict’s syndrome?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewritten_query='What are the 12 cranial nerves listed in anatomical order, including their functions and any notable characteristics?'\n"
     ]
    }
   ],
   "source": [
    "class RewriteQueryAnswer(BaseModel):\n",
    "  rewritten_query: str = Field(description=\"Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\")\n",
    "\n",
    "\n",
    "rewrite_query_parser = PydanticOutputParser(pydantic_object=RewriteQueryAnswer)\n",
    "rewrite_query_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=rewrite_query_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "rewrite_query_template = \"\"\"\n",
    "You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system.\n",
    "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "Rewritten query:\n",
    "\"\"\"\n",
    "rewrite_query_prompt = PromptTemplate(\n",
    "  template=rewrite_query_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': rewrite_query_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "rewrite_query_chain = RunnableParallel(\n",
    "  completion=rewrite_query_prompt | llm | extract_json, prompt_value=rewrite_query_prompt\n",
    ") | RunnableLambda(lambda x: rewrite_query_retry_parser.parse_with_prompt(**x))\n",
    "print(rewrite_query_chain.invoke({'question': 'What is the order of the cranial nerves?'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subqueries=[\"What are the symptoms of Benedict's syndrome?\", \"What are the causes of Benedict's syndrome?\", \"How is Benedict's syndrome diagnosed?\", \"What are the treatment options for Benedict's syndrome?\"]\n"
     ]
    }
   ],
   "source": [
    "class DecompositionAnswer(BaseModel):\n",
    "  subqueries: List[str] = Field(description=\"Given the original query, decompose it into 2-4 simpler sub-queries as json array of strings\")\n",
    "\n",
    "decomposition_parser = PydanticOutputParser(pydantic_object=DecompositionAnswer)\n",
    "decomposition_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=decomposition_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "decomposition_template = \"\"\"\n",
    "You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system.\n",
    "Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query.\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "example: What are the impacts of climate change on the environment?\n",
    "\n",
    "Sub-queries:\n",
    "1. What are the impacts of climate change on biodiversity?\n",
    "2. How does climate change affect the oceans?\n",
    "3. What are the effects of climate change on agriculture?\n",
    "4. What are the impacts of climate change on human health?\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "decomposition_prompt = PromptTemplate(\n",
    "  template=decomposition_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': decomposition_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "decomposition_chain = RunnableParallel(\n",
    "  completion=decomposition_prompt | llm | extract_json, prompt_value=decomposition_prompt\n",
    ") | RunnableLambda(lambda x: decomposition_retry_parser.parse_with_prompt(**x))\n",
    "print(decomposition_chain.invoke({\"question\": \"What is Benedict’s syndrome?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No ranker config provided, no ranker loaded, please load ranker first through load_ranker()\n",
      "WARNING:root:No fuser config provided, no fuser loaded, please load fuser first through load_fuser()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ranker from  /home/super-pc2/.cache/huggingface/hub/llm-blender/PairRM\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "  'cuda'\n",
    "  if torch.cuda.is_available()\n",
    "  else 'mps'\n",
    "  if torch.backends.mps.is_available()\n",
    "  else 'cpu'\n",
    ")\n",
    "blender = llm_blender.Blender()\n",
    "blender.loadranker('llm-blender/PairRM', device=device)\n",
    "blender.loadfuser('llm-blender/gen_fuser_3b', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NMDA receptor is composed of two subunits, GluN1 and GluN2. The GluN1 subunit is essential for the receptor's function and binds glycine, while the GluN2 subunit binds glutamate and determines the receptor's pharmacological properties and kinetics. Each subunit plays a crucial role in the receptor's function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rag_template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(rag_template)\n",
    "\n",
    "gpt_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "openbio_llm = Ollama(model='taozhiyuai/openbiollm-llama-3:70b_q2_k', temperature=0)\n",
    "biomistral_llm = Ollama(model='cniongolo/biomistral', temperature=0)\n",
    "\n",
    "gpt_chain = rag_prompt | gpt_llm | StrOutputParser()\n",
    "openbio_chain = rag_prompt | openbio_llm | StrOutputParser()\n",
    "biomistral_chain = rag_prompt | biomistral_llm | StrOutputParser()\n",
    "\n",
    "def fuse_generations(dict):\n",
    "  question = dict['question']\n",
    "\n",
    "  gpt_res = dict['gpt_res']\n",
    "  openbio_res = dict['openbio_res']\n",
    "  biomistral_res = dict['biomistral_res']\n",
    "  answers = [gpt_res, openbio_res, biomistral_res]\n",
    "\n",
    "  fuse_generations, ranks = blender.rank_and_fuse(\n",
    "    [question],\n",
    "    [answers],\n",
    "    instructions=['keep the similar length of the output as the candidates.'],\n",
    "    return_scores=False,\n",
    "    batch_size=1,\n",
    "    top_k=5,\n",
    "  )\n",
    "  return fuse_generations[0]\n",
    "\n",
    "rag_chain = (\n",
    "  {\n",
    "    'gpt_res': gpt_chain,\n",
    "    'openbio_res': openbio_chain,\n",
    "    'biomistral_res': biomistral_chain,\n",
    "    'question': itemgetter('question')\n",
    "  }\n",
    "  | RunnableLambda(fuse_generations)\n",
    ")\n",
    "\n",
    "final_res = rag_chain.invoke({\"context\": '', \"question\": 'What is subunit composition of NMDA receptors and role of each subunit?'})\n",
    "print(final_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Search Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_med_retriever = PubMedRetriever()\n",
    "pub_med_retriever.invoke('What is the order of the cranial nerves?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arxiv Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/1912.10601v2', 'Published': datetime.date(2021, 3, 13), 'Title': 'Optimized Cranial Bandeau Remodeling', 'Authors': 'James Drake, Marina Drygala, Ricardo Fukasawa, Jochen Koenemann, Andre Linhares, Thomas Looi, John Phillips, David Qian, Nikoo Saber, Justin Toth, Chris Woodbeck, Jessie Yeung'}, page_content=\"Craniosynostosis, a condition affecting 1 in 2000 infants, is caused by\\npremature fusing of cranial vault sutures, and manifests itself in abnormal\\nskull growth patterns. Left untreated, the condition may lead to severe\\ndevelopmental impairment. Standard practice is to apply corrective cranial\\nbandeau remodeling surgery in the first year of the infant's life. The most\\nfrequent type of surgery involves the removal of the so-called fronto-orbital\\nbar from the patient's forehead and the cutting of well-placed incisions to\\nreshape the skull in order to obtain the desired result. In this paper, we\\npropose a precise optimization model for the above cranial bandeau remodeling\\nproblem and its variants. We have developed efficient algorithms that solve\\nbest incision placement, and show hardness for more general cases in the class.\\nTo the best of our knowledge this paper is the first to introduce optimization\\nmodels for craniofacial surgery applications.\"),\n",
       " Document(metadata={'Entry ID': 'http://arxiv.org/abs/1706.07649v1', 'Published': datetime.date(2017, 6, 23), 'Title': 'Computer-aided implant design for the restoration of cranial defects', 'Authors': 'Xiaojun Chen, Lu Xu, Xing Li, Jan Egger'}, page_content='Patient-specific cranial implants are important and necessary in the surgery\\nof cranial defect restoration. However, traditional methods of manual design of\\ncranial implants are complicated and time-consuming. Our purpose is to develop\\na novel software named EasyCrania to design the cranial implants conveniently\\nand efficiently. The process can be divided into five steps, which are\\nmirroring model, clipping surface, surface fitting, the generation of the\\ninitial implant and the generation of the final implant. The main concept of\\nour method is to use the geometry information of the mirrored model as the base\\nto generate the final implant. The comparative studies demonstrated that the\\nEasyCrania can improve the efficiency of cranial implant design significantly.\\nAnd, the intra- and inter-rater reliability of the software were stable, which\\nwere 87.07+/-1.6% and 87.73+/-1.4% respectively.'),\n",
       " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2009.13704v1', 'Published': datetime.date(2020, 9, 29), 'Title': 'Cranial Implant Design via Virtual Craniectomy with Shape Priors', 'Authors': 'Franco Matzkin, Virginia Newcombe, Ben Glocker, Enzo Ferrante'}, page_content='Cranial implant design is a challenging task, whose accuracy is crucial in\\nthe context of cranioplasty procedures. This task is usually performed manually\\nby experts using computer-assisted design software. In this work, we propose\\nand evaluate alternative automatic deep learning models for cranial implant\\nreconstruction from CT images. The models are trained and evaluated using the\\ndatabase released by the AutoImplant challenge, and compared to a baseline\\nimplemented by the organizers. We employ a simulated virtual craniectomy to\\ntrain our models using complete skulls, and compare two different approaches\\ntrained with this procedure. The first one is a direct estimation method based\\non the UNet architecture. The second method incorporates shape priors to\\nincrease the robustness when dealing with out-of-distribution implant shapes.\\nOur direct estimation method outperforms the baselines provided by the\\norganizers, while the model with shape priors shows superior performance when\\ndealing with out-of-distribution cases. Overall, our methods show promising\\nresults in the difficult task of cranial implant design.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_retriever = ArxivRetriever(load_max_docs=3, get_ful_documents=True)\n",
    "arxiv_retriever.invoke('What is the order of the cranial nerves?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI Protein DB retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "  'gene': {\n",
    "    'rettype': 'xml',\n",
    "    'retmode': 'xml',\n",
    "  },\n",
    "  'protein': {\n",
    "    'rettype': 'gb',\n",
    "    'retmode': 'text',\n",
    "  },\n",
    "}\n",
    "\n",
    "class NCBIRetriever(BaseRetriever):\n",
    "  db: str\n",
    "  k: int\n",
    "\n",
    "  def __init__(self, db: str, k: int):\n",
    "    super().__init__(db=db, k=k)\n",
    "\n",
    "    self.db = db\n",
    "    self.k = k\n",
    "\n",
    "    entrez_email = os.getenv('ENTREZ_EMAIL')\n",
    "    if entrez_email == None:\n",
    "      raise ValueError('ENTREZ_EMAIL is not defined')\n",
    "    Entrez.email = entrez_email\n",
    "\n",
    "  def _search(self, term):\n",
    "    handle = Entrez.esearch(db=self.db, term=term, retmax=self.k)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record['IdList']\n",
    "\n",
    "  def _fetch(self, ids):\n",
    "    rettype = db_params[self.db][\"rettype\"]\n",
    "    retmode = db_params[self.db][\"retmode\"]\n",
    "\n",
    "    handle = Entrez.efetch(db=self.db, id=ids, rettype=rettype, retmode=retmode)\n",
    "    if self.db == 'gene':\n",
    "      records = Entrez.read(handle)\n",
    "    else:\n",
    "      records = [SeqIO.read(handle, rettype)]\n",
    "    handle.close()\n",
    "    return records\n",
    "\n",
    "  def _get_gene_document(self, record):\n",
    "    gene_id = record['Entrezgene_track-info']['Gene-track']['Gene-track_geneid']\n",
    "    gene_symbol = record['Entrezgene_gene']['Gene-ref']['Gene-ref_locus']\n",
    "    gene_description = record.get('Entrezgene_summary', 'N/A')\n",
    "    organism_name = record['Entrezgene_source']['BioSource']['BioSource_org']['Org-ref']['Org-ref_taxname']\n",
    "    page_content = (\n",
    "      f'Gene ID: {gene_id}\\n'\n",
    "      f'Gene Symbol: {gene_symbol}\\n'\n",
    "      f'Organism: {organism_name}\\n'\n",
    "      f'Description: {gene_description}'\n",
    "    )\n",
    "    source = f'https://www.ncbi.nlm.nih.gov/gene/{gene_id}'\n",
    "    document = Document(page_content=page_content, metadata={'source': source})\n",
    "    return document\n",
    "\n",
    "  def _get_protein_document(self, record):\n",
    "    molecule_type = record.annotations.get(\"molecule_type\", \"N/A\")\n",
    "    organism = record.annotations.get(\"organism\", \"N/A\")\n",
    "    comment = record.annotations.get(\"comment\", \"N/A\")\n",
    "    page_content = (\n",
    "      f'Protein ID: {record.id}\\n'\n",
    "      f'Type: {molecule_type}\\n'\n",
    "      f'Name: {record.name}\\n'\n",
    "      f'Organism: {organism}\\n'\n",
    "      f'Description: {record.description}\\n'\n",
    "      f'Comment: {comment}\\n'\n",
    "      f'Sequence: {record.seq}'\n",
    "    )\n",
    "    source = f'https://www.ncbi.nlm.nih.gov/protein/{record.id}'\n",
    "    document = Document(page_content=page_content, metadata={'source': source})\n",
    "    return document\n",
    "\n",
    "  def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "    ids = self._search(query)\n",
    "    records = self._fetch(ids)\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for record in records:\n",
    "      if self.db == 'gene':\n",
    "        docs.append(self._get_gene_document(record))\n",
    "      elif self.db == 'protein':\n",
    "        docs.append(self._get_protein_document(record))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/protein/ABW05875.1'}, page_content='Protein ID: ABW05875.1\\nType: protein\\nName: ABW05875\\nOrganism: Bromelia pinguin\\nDescription: PsbN (chloroplast) [Bromelia pinguin]\\nComment: Method: conceptual translation.\\nSequence: METATLVAISISGLLVSFTGYALYTAFGQPSQQLRDPFEEHGD')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_protein_retriever = NCBIRetriever(db='protein', k=3)\n",
    "ncbi_protein_retriever.invoke('ABW05875')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139103289'}, page_content='Gene ID: 139103289\\nGene Symbol: Peng\\nOrganism: Cardiocondyla obscurior\\nDescription: N/A'),\n",
       " Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139085911'}, page_content='Gene ID: 139085911\\nGene Symbol: peng\\nOrganism: Chironomus tepperi\\nDescription: N/A'),\n",
       " Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139048079'}, page_content='Gene ID: 139048079\\nGene Symbol: peng\\nOrganism: Dermacentor albipictus\\nDescription: N/A')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_gene_retriever = NCBIRetriever(db='gene', k=3)\n",
    "ncbi_gene_retriever.invoke('peng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI Protein DB chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/protein/ABW05875.1'}, page_content='Protein ID: ABW05875.1\\nType: protein\\nName: ABW05875\\nOrganism: Bromelia pinguin\\nDescription: PsbN (chloroplast) [Bromelia pinguin]\\nComment: Method: conceptual translation.\\nSequence: METATLVAISISGLLVSFTGYALYTAFGQPSQQLRDPFEEHGD')]\n"
     ]
    }
   ],
   "source": [
    "class NCBIProteinDBAnswer(BaseModel):\n",
    "  query: str = Field(description='Given the original query, please find a protein locus for the NCBI protein database.')\n",
    "\n",
    "ncbi_protein_db_parser = PydanticOutputParser(pydantic_object=NCBIProteinDBAnswer)\n",
    "ncbi_protein_db_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=ncbi_protein_db_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "ncbi_protein_db_template = \"\"\"\n",
    "As an expert in bioinformatics and user query optimization for biological databases, your task is to transform user questions into precise and effective queries suitable for the NCBI protein database.\n",
    "Create a query with only locus of a protein for search within the NCBI protein database.\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "ncbi_protein_db_prompt = PromptTemplate(\n",
    "  template=ncbi_protein_db_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': ncbi_protein_db_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "query_extractor = lambda res: res.query\n",
    "\n",
    "ncbi_protein_db_chain = RunnableParallel(\n",
    "  completion=ncbi_protein_db_prompt | llm | extract_json, prompt_value=ncbi_protein_db_prompt\n",
    ") | RunnableLambda(lambda x: ncbi_protein_db_retry_parser.parse_with_prompt(**x)) | query_extractor | ncbi_protein_retriever\n",
    "print(ncbi_protein_db_chain.invoke({\"question\": \"Calculate the frequency of each amino acid in the ABW05875 protein sequence\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI Gene DB chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139103289'}, page_content='Gene ID: 139103289\\nGene Symbol: Peng\\nOrganism: Cardiocondyla obscurior\\nDescription: N/A'), Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139085911'}, page_content='Gene ID: 139085911\\nGene Symbol: peng\\nOrganism: Chironomus tepperi\\nDescription: N/A'), Document(metadata={'source': 'https://www.ncbi.nlm.nih.gov/gene/139048079'}, page_content='Gene ID: 139048079\\nGene Symbol: peng\\nOrganism: Dermacentor albipictus\\nDescription: N/A')]\n"
     ]
    }
   ],
   "source": [
    "class NCBIGeneDBAnswer(BaseModel):\n",
    "  query: str = Field(description='Given the original query, please find a gene locus for the NCBI gene database.')\n",
    "\n",
    "ncbi_gene_db_parser = PydanticOutputParser(pydantic_object=NCBIGeneDBAnswer)\n",
    "ncbi_gene_db_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=ncbi_gene_db_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "ncbi_gene_db_template = \"\"\"\n",
    "As an expert in bioinformatics and user query optimization for biological databases, your task is to transform user questions into precise and effective queries suitable for the NCBI gene database.\n",
    "Create a query with only locus of a gene for search within the NCBI gene database.\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "ncbi_gene_db_prompt = PromptTemplate(\n",
    "  template=ncbi_gene_db_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': ncbi_gene_db_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "query_extractor = lambda res: res.query\n",
    "\n",
    "ncbi_gene_db_chain = RunnableParallel(\n",
    "  completion=ncbi_gene_db_prompt | llm | extract_json, prompt_value=ncbi_gene_db_prompt\n",
    ") | RunnableLambda(lambda x: ncbi_gene_db_retry_parser.parse_with_prompt(**x)) | query_extractor | ncbi_gene_retriever\n",
    "print(ncbi_gene_db_chain.invoke({\"question\": \"Calculate the frequency of each amino acid in the peng gene sequence\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "  question: str\n",
    "\n",
    "  specialized_srcs: List[str]\n",
    "\n",
    "  step_back_query: str\n",
    "  rewritten_query: str\n",
    "  subqueries: List[str]\n",
    "\n",
    "  generated_docs: List[str]\n",
    "\n",
    "  documents: Annotated[list, operator.add]\n",
    "\n",
    "  web_search: str\n",
    "\n",
    "  generation: str\n",
    "  generations_num: int\n",
    "\n",
    "def determine_specialized_srcs(state):\n",
    "  print('---DETERMINE SPECIALIZED SOURCES---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  try:\n",
    "    res = question_router.invoke({'question': question})\n",
    "    srcs = [src.strip().lower() for src in res.sources]\n",
    "  except:\n",
    "    srcs = []\n",
    "\n",
    "  return {'specialized_srcs': srcs}\n",
    "\n",
    "def route_question(state):\n",
    "  print('---ROUTE QUESTION---')\n",
    "\n",
    "  sources = state['specialized_srcs']\n",
    "\n",
    "  if len(sources) == 0:\n",
    "    print('---ROUTE QUESTION TO WEB SEARCH---')\n",
    "    return 'websearch'\n",
    "  else:\n",
    "    print(f'---ROUTE QUESTION TO SPECIALIZED SOURCES: {\", \".join([source.upper() for source in sources])}---')\n",
    "    return 'specialized_srcs'\n",
    "\n",
    "def generate_step_back_query(state):\n",
    "  print('---GENERATE STEP-BACK QUERY---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  try:\n",
    "    response = step_back_chain.invoke({'question': question})\n",
    "    step_back_query = response.step_back\n",
    "  except:\n",
    "    step_back_query = question\n",
    "\n",
    "  return {'step_back_query': step_back_query}\n",
    "\n",
    "def generate_rewritten_query(state):\n",
    "  print('---GENERATE REWRITTEN QUERY---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  try:\n",
    "    response = rewrite_query_chain.invoke({'question': question})\n",
    "    rewritten_query = response.rewritten_query\n",
    "  except:\n",
    "    rewritten_query = question\n",
    "\n",
    "  return {'rewritten_query': rewritten_query}\n",
    "\n",
    "def generate_subqueries(state):\n",
    "  print('---GENERATE SUBQUERIES---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  try:\n",
    "    decomposition_answer = decomposition_chain.invoke({'question': question})\n",
    "    subqueries = decomposition_answer.subqueries\n",
    "    # Limit to a maximum of four subqueries\n",
    "    subqueries = subqueries[:4]\n",
    "  except:\n",
    "    subqueries = []\n",
    "\n",
    "  print(f'---FINAL SUBQUERIES NUMBER: {len(subqueries)}---')\n",
    "\n",
    "  return {'subqueries': subqueries}\n",
    "\n",
    "def generate_hyde_docs(state):\n",
    "  print('---GENERATE HYDE DOCUMENTS---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  subqueries = state['subqueries']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query, *subqueries]\n",
    "  generated_docs = []\n",
    "\n",
    "  for query in queries:\n",
    "    generated_doc = hyde_chain.invoke({'question': query})\n",
    "    generated_docs.append(generated_doc)\n",
    "\n",
    "  return {'question': question, 'generated_docs': generated_docs}\n",
    "\n",
    "def vector_store_retriever_node(state):\n",
    "  generated_docs = state['generated_docs']\n",
    "  specialized_srcs = state['specialized_srcs']\n",
    "\n",
    "  if 'vectorstore' not in specialized_srcs:\n",
    "    return {'documents': []}\n",
    "\n",
    "  print('---RETRIEVE FROM VECTOR STORE---')\n",
    "\n",
    "  documents = []\n",
    "\n",
    "  for generated_doc in generated_docs:\n",
    "    documents.extend(retriever.invoke(generated_doc))\n",
    "\n",
    "  return {'documents': documents}\n",
    "\n",
    "def pub_med_retriever_node(state):\n",
    "  specialized_srcs = state['specialized_srcs']\n",
    "\n",
    "  if 'pubmed' not in specialized_srcs:\n",
    "    return {'documents': []}\n",
    "\n",
    "  print('---RETRIEVE FROM PUBMED---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  subqueries = state['subqueries']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query, *subqueries]\n",
    "  documents = []\n",
    "\n",
    "  for query in queries:\n",
    "    try:\n",
    "      documents.extend(pub_med_retriever.invoke(query))\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return {'documents': documents}\n",
    "\n",
    "def arxiv_retriever_node(state):\n",
    "  specialized_srcs = state['specialized_srcs']\n",
    "\n",
    "  if 'arxiv' not in specialized_srcs:\n",
    "    return {'documents': []}\n",
    "\n",
    "  print('---RETRIEVE FROM ARXIV---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  subqueries = state['subqueries']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query, *subqueries]\n",
    "  documents = []\n",
    "\n",
    "  for query in queries:\n",
    "    try:\n",
    "      documents.extend(arxiv_retriever.invoke(query))\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return {'documents': documents}\n",
    "\n",
    "def ncbi_protein_db_retriever_node(state):\n",
    "  specialized_srcs = state['specialized_srcs']\n",
    "\n",
    "  if 'ncbi_protein' not in specialized_srcs:\n",
    "    return {'documents': []}\n",
    "\n",
    "  print('---RETRIEVE FROM NCBI PROTEIN DB---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  subqueries = state['subqueries']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query, *subqueries]\n",
    "  documents = []\n",
    "\n",
    "  for query in queries:\n",
    "    try:\n",
    "      documents.extend(ncbi_protein_db_chain.invoke(query))\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return {'documents': documents}\n",
    "\n",
    "def ncbi_gene_db_retriever_node(state):\n",
    "  specialized_srcs = state['specialized_srcs']\n",
    "\n",
    "  if 'ncbi_gene' not in specialized_srcs:\n",
    "    return {'documents': []}\n",
    "\n",
    "  print('---RETRIEVE FROM NCBI GENE DB---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  subqueries = state['subqueries']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query, *subqueries]\n",
    "  documents = []\n",
    "\n",
    "  for query in queries:\n",
    "    try:\n",
    "      documents.extend(ncbi_gene_db_chain.invoke(query))\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return {'documents': documents}\n",
    "\n",
    "def grade_documents(state):\n",
    "  print('---CHECK DOCUMENT RELEVANCE TO QUESTION---')\n",
    "\n",
    "  rewritten_query = state['rewritten_query']\n",
    "  documents = state['documents']\n",
    "\n",
    "  print(f'---INITIAL DOCUMENTS NUMBER: {len(documents)}---')\n",
    "\n",
    "  if len(documents) == 0:\n",
    "    return {'documents': [], 'web_search': True}\n",
    "\n",
    "  unique_documents = list({doc.page_content: doc for doc in documents}.values())\n",
    "  retriever = BM25Retriever.from_documents(unique_documents)\n",
    "  retrieved_documents = retriever.invoke(rewritten_query)\n",
    "  filtered_documents = []\n",
    "  web_search = False\n",
    "\n",
    "  for index, document in enumerate(retrieved_documents):\n",
    "    print(f'---GRADE DOCUMENT ({index + 1}/{len(retrieved_documents)})---')\n",
    "\n",
    "    try:\n",
    "      score = docs_grader_chain.invoke({\n",
    "        'question': rewritten_query,\n",
    "        'document': document.page_content,\n",
    "      })\n",
    "      grade = score.binary_score\n",
    "    except:\n",
    "      grade = 'No'\n",
    "\n",
    "    if grade.lower() == 'yes':\n",
    "      print('---GRADE: DOCUMENT RELEVANT---')\n",
    "      filtered_documents.append(document)\n",
    "    else:\n",
    "      print('---GRADE: DOCUMENT NOT RELEVANT---')\n",
    "      web_search = True\n",
    "\n",
    "  print(f'---FINAL DOCUMENTS NUMBER: {len(filtered_documents)}---')\n",
    "\n",
    "  state['documents'].clear()\n",
    "  return {\n",
    "    'documents': filtered_documents,\n",
    "    'web_search': web_search or len(filtered_documents) == 0,\n",
    "  }\n",
    "\n",
    "def decide_to_generate(state):\n",
    "  print('---ASSESS GRADED DOCUMENTS---')\n",
    "\n",
    "  web_search = state['web_search']\n",
    "\n",
    "  if web_search:\n",
    "    print('---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---')\n",
    "    return 'websearch'\n",
    "  else:\n",
    "    print('---DECISION: GENERATE---')\n",
    "    return 'generate'\n",
    "\n",
    "def web_search(state):\n",
    "  print('---WEB SEARCH---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  web_results = web_search_tool.invoke({'query': question})\n",
    "  docs = [Document(page_content=result['content'], metadata={'source': result['url']}) for result in web_results]\n",
    "\n",
    "  return {'documents': docs}\n",
    "\n",
    "def generate(state):\n",
    "  print('---GENERATE---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state['documents']\n",
    "  generations_num = state.get('generations_num', 0)\n",
    "\n",
    "  context = '\\n\\n'.join(map(lambda doc: doc.page_content, documents))\n",
    "  generation = rag_chain.invoke({'context': context, 'question': question})\n",
    "\n",
    "  return {'generation': generation, 'generations_num': generations_num + 1}\n",
    "\n",
    "def grade_generation(state):\n",
    "  print('---CHECK HALLUCINATIONS---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state['documents']\n",
    "  generation = state['generation']\n",
    "  generations_num = state['generations_num']\n",
    "\n",
    "  if generations_num >= 2:\n",
    "    return 'useful'\n",
    "\n",
    "  try:\n",
    "    context = '\\n\\n'.join(map(lambda doc: doc.page_content, documents))\n",
    "    score = hallucination_grader.invoke({\n",
    "      'documents': context,\n",
    "      'generation': generation,\n",
    "    })\n",
    "    grade = score.binary_score\n",
    "  except:\n",
    "    grade = 'no'\n",
    "\n",
    "  if grade == 'yes':\n",
    "    print('---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---')\n",
    "    print('---GRADE GENERATION vs QUESTION---')\n",
    "\n",
    "    try:\n",
    "      score = answer_grader.invoke({'question': question,'generation': generation})\n",
    "      grade = score.binary_score\n",
    "    except:\n",
    "      grade = 'no'\n",
    "\n",
    "    if grade == 'yes':\n",
    "      print('---DECISION: GENERATION ADDRESSES QUESTION---')\n",
    "      return 'useful'\n",
    "    else:\n",
    "      print('---DECISION: GENERATION DOES NOT ADDRESS QUESTION---')\n",
    "      return 'not useful'\n",
    "  else:\n",
    "    print('---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---')\n",
    "    return 'not supported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x73fdea1bfd00>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node('determine_specialized_srcs', determine_specialized_srcs)\n",
    "\n",
    "workflow.add_node('generate_step_back_query', generate_step_back_query)\n",
    "workflow.add_node('generate_rewritten_query', generate_rewritten_query)\n",
    "workflow.add_node('generate_subqueries', generate_subqueries)\n",
    "\n",
    "workflow.add_node('generate_hyde_docs', generate_hyde_docs)\n",
    "\n",
    "workflow.add_node('vector_store_retriever', vector_store_retriever_node)\n",
    "workflow.add_node('pub_med_retriever', pub_med_retriever_node)\n",
    "workflow.add_node('arxiv_retriever', arxiv_retriever_node)\n",
    "workflow.add_node('ncbi_protein_db_retriever', ncbi_protein_db_retriever_node)\n",
    "workflow.add_node('ncbi_gene_db_retriever_node', ncbi_gene_db_retriever_node)\n",
    "\n",
    "workflow.add_node('websearch', web_search)\n",
    "workflow.add_node('generate', generate)\n",
    "workflow.add_node('grade_documents', grade_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x73fdea1bfd00>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, 'determine_specialized_srcs')\n",
    "workflow.add_conditional_edges(\n",
    "  'determine_specialized_srcs',\n",
    "  route_question,\n",
    "  {\n",
    "    'websearch': 'websearch',\n",
    "    'specialized_srcs': 'generate_step_back_query',\n",
    "  },\n",
    ")\n",
    "\n",
    "workflow.add_edge('generate_step_back_query', 'generate_rewritten_query')\n",
    "workflow.add_edge('generate_rewritten_query', 'generate_subqueries')\n",
    "workflow.add_edge('generate_subqueries', 'generate_hyde_docs')\n",
    "\n",
    "workflow.add_edge('generate_hyde_docs', 'vector_store_retriever')\n",
    "workflow.add_edge('generate_hyde_docs', 'pub_med_retriever')\n",
    "workflow.add_edge('generate_hyde_docs', 'arxiv_retriever')\n",
    "workflow.add_edge('generate_hyde_docs', 'ncbi_protein_db_retriever')\n",
    "workflow.add_edge('generate_hyde_docs', 'ncbi_gene_db_retriever_node')\n",
    "\n",
    "workflow.add_edge('vector_store_retriever', 'grade_documents')\n",
    "workflow.add_edge('pub_med_retriever', 'grade_documents')\n",
    "workflow.add_edge('arxiv_retriever', 'grade_documents')\n",
    "workflow.add_edge('ncbi_protein_db_retriever', 'grade_documents')\n",
    "workflow.add_edge('ncbi_gene_db_retriever_node', 'grade_documents')\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "  'grade_documents',\n",
    "  decide_to_generate,\n",
    "  {\n",
    "    'websearch': 'websearch',\n",
    "    'generate': 'generate',\n",
    "  },\n",
    ")\n",
    "workflow.add_edge('websearch', 'generate')\n",
    "workflow.add_conditional_edges(\n",
    "  'generate',\n",
    "  grade_generation,\n",
    "  {\n",
    "    'not supported': 'generate',\n",
    "    'useful': END,\n",
    "    'not useful': 'websearch',\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_PROTEIN---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM NCBI PROTEIN DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 3---\n",
      "---GRADE DOCUMENT (1/1)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Count each amino acid in the ABW05875 sequence',\n",
       " 'specialized_srcs': ['ncbi_protein'],\n",
       " 'step_back_query': 'What are the general characteristics of protein sequences like ABW05875?',\n",
       " 'rewritten_query': 'Count each amino acid in the ABW05875 sequence',\n",
       " 'subqueries': ['What are the counts of each amino acid type (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y) in the ABW05875 sequence?',\n",
       "  'How many occurrences of each amino acid are there in the ABW05875 sequence?',\n",
       "  'What is the frequency distribution of each amino acid type in the ABW05875 sequence?'],\n",
       " 'generated_docs': ['Here is a scientific paper-style passage answering the question:\\n\\n**Title:** Amino Acid Composition Analysis of the ABW05875 Sequence\\n\\n**Abstract:**\\nThe ABW05875 protein sequence, a member of the hypothetical protein family, has been analyzed to determine its amino acid composition. This study aimed to count and quantify each amino acid present in the ABW05875 sequence.\\n\\n**Results:**\\n\\nTo perform the analysis, we utilized bioinformatics tools to extract the amino acid sequence from the UniProt database (UniProt Consortium, 2022). The resulting sequence was then subjected to a comprehensive amino acid composition analysis using a custom Python script. The results are presented in Table 1 below:\\n\\n| Amino Acid | Count |\\n| --- | --- |\\n| Alanine (A) | 12 |\\n| Arginine (R) | 8 |\\n| Asparagine (N) | 5 |\\n| Aspartic acid (D) | 9 |\\n| Cysteine (C) | 2 |\\n| Glutamic acid (E) | 11 |\\n| Glutamine (Q) | 7 |\\n| Glycine (G) | 15 |\\n| Histidine (H) | 4 |\\n| Isoleucine (I) | 6 |\\n| Leucine (L) | 10 |\\n| Lysine (K) | 9 |\\n| Methionine (M) | 3 |\\n| Phenylalanine (F) | 5 |\\n| Proline (P) | 8 |\\n| Serine (S) | 7 |\\n| Threonine (T) | 6 |\\n| Tryptophan (W) | 2 |\\n| Tyrosine (Y) | 4 |\\n| Valine (V) | 12 |\\n\\n**Discussion:**\\nThe amino acid composition analysis of the ABW05875 sequence reveals a diverse range of amino acids, with Glycine (G) being the most abundant (15 occurrences). This is consistent with previous studies on hypothetical protein sequences, which often exhibit high levels of glycine and other small amino acids. The presence of cysteine (C), tryptophan (W), and tyrosine (Y) suggests that ABW05875 may have important structural or functional roles in the cell.\\n\\n**Conclusion:**\\nIn conclusion, this study provides a comprehensive analysis of the amino acid composition of the ABW05875 sequence. The results will be useful for further studies on protein structure, function, and evolution.\\n\\nReferences:\\nUniProt Consortium (2022). UniProt: the universal protein resource. Nucleic Acids Research, 50(D1), D449-D456.',\n",
       "  'Here is a potential scientific paper passage that answers the question:\\n\\n**Title:** Characterization of Protein Sequence ABW05875 and Its Homologs\\n\\n**Abstract:**\\n\\nThe protein sequence ABW05875 (UniProt ID) has been identified as a member of a larger family of proteins with conserved functional domains. To better understand its characteristics, we conducted a comprehensive analysis of the primary structure and predicted properties of this protein.\\n\\n**Results:**\\n\\nProtein sequence ABW05875 is a 245-amino acid polypeptide with a molecular weight of approximately 27 kDa. Sequence alignment and phylogenetic analysis revealed that ABW05875 shares significant similarity (35-40% identity) with other proteins in the Pfam family PF13523, which includes enzymes involved in the metabolism of small molecules. The sequence contains several conserved motifs, including a putative ATP-binding site and a predicted coiled-coil domain.\\n\\n**Discussion:**\\n\\nThe general characteristics of protein sequences like ABW05875 are summarized as follows:\\n\\n* **Length:** Typically 200-300 amino acids\\n* **Molecular weight:** Approximately 20-30 kDa\\n* **Sequence similarity:** Share significant identity (35-40%) with other proteins in the Pfam family PF13523\\n* **Functional domains:** Contain conserved motifs, including ATP-binding sites and coiled-coil domains\\n* **Predicted function:** Involved in the metabolism of small molecules, potentially as enzymes or regulatory proteins\\n\\nThese characteristics suggest that protein sequences like ABW05875 are likely to be involved in cellular processes related to energy metabolism and molecular transport. Further experimental studies are needed to confirm their functional roles and potential applications.',\n",
       "  'Here is a scientific paper-style passage answering the question:\\n\\n**Title:** Amino Acid Composition Analysis of the ABW05875 Sequence\\n\\n**Abstract:**\\nThe ABW05875 protein sequence, a member of the hypothetical protein family, has been analyzed to determine its amino acid composition. This study aimed to count and quantify each amino acid present in the ABW05875 sequence.\\n\\n**Results:**\\n\\nTo perform the analysis, we utilized bioinformatics tools to extract the amino acid sequence from the UniProt database (UniProt Consortium, 2022). The resulting sequence was then subjected to a comprehensive amino acid composition analysis using a custom Python script. The results are presented in Table 1 below:\\n\\n| Amino Acid | Count |\\n| --- | --- |\\n| Alanine (A) | 12 |\\n| Arginine (R) | 8 |\\n| Asparagine (N) | 5 |\\n| Aspartic acid (D) | 9 |\\n| Cysteine (C) | 2 |\\n| Glutamic acid (E) | 11 |\\n| Glutamine (Q) | 7 |\\n| Glycine (G) | 15 |\\n| Histidine (H) | 4 |\\n| Isoleucine (I) | 6 |\\n| Leucine (L) | 10 |\\n| Lysine (K) | 9 |\\n| Methionine (M) | 3 |\\n| Phenylalanine (F) | 5 |\\n| Proline (P) | 8 |\\n| Serine (S) | 7 |\\n| Threonine (T) | 6 |\\n| Tryptophan (W) | 2 |\\n| Tyrosine (Y) | 4 |\\n| Valine (V) | 12 |\\n\\n**Discussion:**\\nThe amino acid composition analysis of the ABW05875 sequence reveals a diverse range of amino acids, with Glycine (G) being the most abundant (15 occurrences). This is consistent with previous studies on hypothetical protein sequences, which often exhibit high levels of glycine and other small amino acids. The presence of cysteine (C), tryptophan (W), and tyrosine (Y) suggests that ABW05875 may have important structural or functional roles in the cell.\\n\\n**Conclusion:**\\nIn conclusion, this study provides a comprehensive analysis of the amino acid composition of the ABW05875 sequence. The results will be useful for further studies on protein structure, function, and evolution.\\n\\nReferences:\\nUniProt Consortium (2022). UniProt: the universal protein resource. Nucleic Acids Research, 50(D1), D449-D456.',\n",
       "  'Here is a scientific paper passage that answers the question:\\n\\n**Title:** Amino Acid Composition Analysis of the ABW05875 Sequence\\n\\n**Abstract:**\\n\\nThe ABW05875 protein sequence has been analyzed to determine its amino acid composition. This study aimed to identify and quantify the presence of each amino acid type in the given sequence.\\n\\n**Results:**\\n\\nTo perform this analysis, we utilized a bioinformatics approach using the ABW05875 protein sequence (accession number: ABW05875). The sequence was subjected to amino acid composition analysis using a custom Python script. The results are presented in Table 1 below:\\n\\n| Amino Acid Type | Count |\\n| --- | --- |\\n| Alanine (A) | 12 |\\n| Cysteine (C) | 5 |\\n| Aspartic Acid (D) | 8 |\\n| Glutamic Acid (E) | 15 |\\n| Phenylalanine (F) | 3 |\\n| Glycine (G) | 9 |\\n| Histidine (H) | 2 |\\n| Isoleucine (I) | 6 |\\n| Lysine (K) | 10 |\\n| Leucine (L) | 18 |\\n| Methionine (M) | 4 |\\n| Asparagine (N) | 7 |\\n| Proline (P) | 5 |\\n| Glutamine (Q) | 12 |\\n| Arginine (R) | 11 |\\n| Serine (S) | 14 |\\n| Threonine (T) | 8 |\\n| Valine (V) | 16 |\\n| Tryptophan (W) | 1 |\\n| Tyrosine (Y) | 2 |\\n\\n**Discussion:**\\n\\nThe results of this analysis reveal a diverse amino acid composition in the ABW05875 sequence. The most abundant amino acids are Leucine (L), Valine (V), and Serine (S), which account for approximately 40% of the total amino acid count. This suggests that the protein may have structural or functional properties related to these amino acids.\\n\\n**Conclusion:**\\n\\nIn conclusion, this study provides a comprehensive analysis of the amino acid composition in the ABW05875 sequence. The results can be used as a reference for further studies on the structure and function of this protein.',\n",
       "  'Here is a scientific paper-style passage answering the question:\\n\\n**Title:** Amino Acid Composition Analysis of the ABW05875 Sequence\\n\\n**Abstract:**\\nThe ABW05875 protein sequence, accessioned in various databases, has been analyzed to determine its amino acid composition. This study aimed to quantify the occurrences of each amino acid within this sequence.\\n\\n**Results:**\\n\\nTo investigate the amino acid composition of the ABW05875 sequence, we employed a straightforward approach using standard bioinformatics tools. The sequence was first retrieved from the relevant database and then subjected to analysis using a custom-written script in Python. The results are presented in Table 1 below:\\n\\n| Amino Acid | Frequency |\\n| --- | --- |\\n| Alanine (A) | 23 |\\n| Arginine (R) | 17 |\\n| Asparagine (N) | 12 |\\n| Aspartic acid (D) | 15 |\\n| Cysteine (C) | 8 |\\n| Glutamic acid (E) | 20 |\\n| Glutamine (Q) | 10 |\\n| Glycine (G) | 25 |\\n| Histidine (H) | 12 |\\n| Isoleucine (I) | 18 |\\n| Leucine (L) | 22 |\\n| Lysine (K) | 19 |\\n| Methionine (M) | 9 |\\n| Phenylalanine (F) | 15 |\\n| Proline (P) | 11 |\\n| Serine (S) | 18 |\\n| Threonine (T) | 12 |\\n| Tryptophan (W) | 5 |\\n| Tyrosine (Y) | 10 |\\n| Valine (V) | 20 |\\n\\n**Discussion:**\\nThe results indicate that the ABW05875 sequence is rich in hydrophobic amino acids, such as Leucine (L), Isoleucine (I), and Valine (V), which are essential for protein stability and folding. Conversely, the presence of polar residues like Serine (S) and Threonine (T) suggests potential roles in protein-protein interactions or enzymatic activity.\\n\\n**Conclusion:**\\nThis study provides a comprehensive analysis of the amino acid composition of the ABW05875 sequence, offering valuable insights into its structural and functional properties. The results can be used as a reference for further studies on this protein sequence.',\n",
       "  \"Here's a potential scientific paper passage that answers the question:\\n\\n**Title:** Characterization of the Amino Acid Composition of the ABW05875 Sequence\\n\\n**Abstract:**\\n\\nThe ABW05875 sequence, a protein of unknown function, has been analyzed to determine its amino acid composition. Using bioinformatics tools and statistical methods, we have calculated the frequency distribution of each amino acid type in this sequence.\\n\\n**Results:**\\n\\nTo investigate the amino acid composition of the ABW05875 sequence, we employed a sliding window approach with a window size of 100 amino acids. The resulting frequency distributions for each amino acid type are presented in Table 1 and Figure 1.\\n\\n| Amino Acid | Frequency (%) |\\n| --- | --- |\\n| Alanine (A) | 12.5 ± 2.1 |\\n| Arginine (R) | 8.3 ± 1.4 |\\n| Asparagine (N) | 9.7 ± 1.6 |\\n| Aspartic Acid (D) | 11.9 ± 2.0 |\\n| Cysteine (C) | 2.5 ± 0.6 |\\n| Glutamic Acid (E) | 13.4 ± 2.3 |\\n| Glutamine (Q) | 7.1 ± 1.2 |\\n| Glycine (G) | 10.9 ± 1.9 |\\n| Histidine (H) | 5.6 ± 1.0 |\\n| Isoleucine (I) | 4.8 ± 0.9 |\\n| Leucine (L) | 7.3 ± 1.2 |\\n| Lysine (K) | 10.3 ± 1.8 |\\n| Methionine (M) | 3.5 ± 0.7 |\\n| Phenylalanine (F) | 4.9 ± 0.9 |\\n| Proline (P) | 6.2 ± 1.1 |\\n| Serine (S) | 11.1 ± 1.9 |\\n| Threonine (T) | 8.5 ± 1.5 |\\n| Tryptophan (W) | 1.4 ± 0.3 |\\n| Tyrosine (Y) | 2.9 ± 0.6 |\\n| Valine (V) | 7.9 ± 1.4 |\\n\\n**Discussion:**\\n\\nThe frequency distribution of each amino acid type in the ABW05875 sequence reveals a relatively balanced composition, with no single amino acid dominating the others. The most abundant amino acids are Glutamic Acid (13.4%), Lysine (10.3%), and Aspartic Acid (11.9%). These results suggest that the ABW05875 protein may have a diverse range of functional properties, potentially involving multiple enzymatic or structural roles.\\n\\n**Conclusion:**\\n\\nIn conclusion, our analysis has provided a comprehensive characterization of the amino acid composition of the ABW05875 sequence. The frequency distribution of each amino acid type will be useful for predicting the protein's structure and function, as well as informing future experimental studies aimed at elucidating its biological role.\"],\n",
       " 'documents': [Document(metadata={'source': 'https://uk.mathworks.com/help/bioinfo/ref/aacount.html'}, page_content='Count amino acids in a sequence [`countStruct`](https://uk.mathworks.com/help/bioinfo/ref/aacount.html#mw_404fc65d-c6ba-4983-b689-1d2350c7a4ba) = aacount([`SeqAA`](https://uk.mathworks.com/help/bioinfo/ref/aacount.html#mw_a6707376-a71b-4224-a43e-04d4bec71590)) counts the number of each type of amino acid in SeqAA, an amino acid sequence, and returns the counts in countStruct, a 1-by-1 MATLAB® structure containing fields for the standard 20 amino acids (A, R, N, D, C, Q, E, G, H, I, L, K, M, F, P, S, T, W, Y, and V). For example, countStruct = aacount(SeqAA,Chart=\"pie\") creates a pie chart showing relative proportions of the amino acids. Count the amino acids in the sequence, and display the results in a pie chart. Ambiguous amino acid characters (B, Z, or X), gaps that are indicated by a hyphens (-), and end terminators (*) are ignored by default.'),\n",
       "  Document(metadata={'source': 'https://www.chegg.com/homework-help/questions-and-answers/want-count-number-occurrences-amino-acid-protein-sequence-write-function-aminoacidcounts-t-q91491852'}, page_content='Question: You want to count the number of occurrences of each amino acid in the protein sequence: Write a function, aminoacid_counts, which takes one argument: 1. A string, which represents the protein sequence. The function must return: • A dictionary in which keys are the different amino acids in the sequence.'),\n",
       "  Document(metadata={'source': 'https://www.mathworks.com/help/bioinfo/ref/aacount.html'}, page_content='Count amino acids in sequence counts the number of each type of amino acid in SeqAA, an amino acid sequence, and returns the counts in countStruct, a 1-by-1 MATLABÂ® structure containing fields for the standard 20 amino acids Count amino acids in a sequence Count the amino acids in the sequence, and display the results in a pie chart. SeqAA â\\x80\\x94 Amino acid sequence character vector | string scalar | row vector of positive integers | structure Amino acid sequence, specified as one of the following. Row vector of integers specifying an amino acid sequence. Structure that contains an amino acid sequence in the countStruct â\\x80\\x94 Total count of amino acids structure Total amino acid count, returned as a structure.'),\n",
       "  Document(metadata={'source': 'https://www.biochemithon.in/biology/bioinformatics/how-to-count-amino-acid-in-a-protein-sequence-using-python-program/'}, page_content='In this article, we are going to learn how python can be useful in finding amino acid in a given protein sequence. Before reading this article you must know about FASTA format and single letter code for the amino acid. (Click here FASTA format)Here, we will learn how can we find the total length of a sequence and find the number of the specific amino acid in a sequence.'),\n",
       "  Document(metadata={'source': 'https://stackoverflow.com/questions/14397504/how-to-count-amino-acids-in-fasta-formated-file'}, page_content='Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Ask questions, find answers and collaborate at work with Stack Overflow for Teams. is it possible to count sequences in this sequence, I mean: with my example: MRMRGRRLLPIIL I would like to have output like this: M - 2, R - 2, RR - 2, G - 1, LL - 2, P - 1, I - 2, L - 1 ? 2Parsing fasta file with biopython to count number sequence reads belonging to each ID 1How to count sequences in a fasta file using Bioperl')],\n",
       " 'web_search': True,\n",
       " 'generation': \"I'm sorry, but as an AI language model, I don't have access to the ABW05875 sequence. Could you please provide me with the sequence so that I can count each amino acid for you?\",\n",
       " 'generations_num': 2}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({'question': 'Count each amino acid in the ABW05875 sequence'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the afferent cranial nerve nuclei?</td>\n",
       "      <td>Trigeminal sensory nucleus- fibres carry gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the order of the cranial nerves ?</td>\n",
       "      <td>1-olfactory\\n2-optic\\n3-oculomotor\\n4-trochlea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the efferent cranial nerve nuclei?</td>\n",
       "      <td>Edinger-westphal nucleus\\nOculomotor nucleus\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which nuclei share the embryo logical origin -...</td>\n",
       "      <td>Oculomotor nucleus Trochlear nucleus Abducens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which nuclei share the embryo logical origin- ...</td>\n",
       "      <td>Trigeminal motor nucleus Facial motor nucleus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>What are the functions each of these structure...</td>\n",
       "      <td>Cortex is involved in perception Hypothalamus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>What are the stimuli for olfaction ?</td>\n",
       "      <td>Airborne molecules \\nAlcohols \\nEsters \\nAroma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>What percentage of human genome are involved w...</td>\n",
       "      <td>3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>What is the difference between threshold value...</td>\n",
       "      <td>Lipid soluble have low thresholds while water ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>What are the 3 main cell types involved in olf...</td>\n",
       "      <td>Olfactory receptors - site of transduction Sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0          What are the afferent cranial nerve nuclei?   \n",
       "1            What is the order of the cranial nerves ?   \n",
       "2          What are the efferent cranial nerve nuclei?   \n",
       "3    Which nuclei share the embryo logical origin -...   \n",
       "4    Which nuclei share the embryo logical origin- ...   \n",
       "..                                                 ...   \n",
       "495  What are the functions each of these structure...   \n",
       "496               What are the stimuli for olfaction ?   \n",
       "497  What percentage of human genome are involved w...   \n",
       "498  What is the difference between threshold value...   \n",
       "499  What are the 3 main cell types involved in olf...   \n",
       "\n",
       "                                                answer  \n",
       "0    Trigeminal sensory nucleus- fibres carry gener...  \n",
       "1    1-olfactory\\n2-optic\\n3-oculomotor\\n4-trochlea...  \n",
       "2    Edinger-westphal nucleus\\nOculomotor nucleus\\n...  \n",
       "3    Oculomotor nucleus Trochlear nucleus Abducens ...  \n",
       "4    Trigeminal motor nucleus Facial motor nucleus ...  \n",
       "..                                                 ...  \n",
       "495  Cortex is involved in perception Hypothalamus ...  \n",
       "496  Airborne molecules \\nAlcohols \\nEsters \\nAroma...  \n",
       "497                                                 3%  \n",
       "498  Lipid soluble have low thresholds while water ...  \n",
       "499  Olfactory receptors - site of transduction Sup...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_csv('brainscape.csv')[:500]\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cached RAGs responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_path = Path('cache.json')\n",
    "\n",
    "if not os.path.exists(cache_path):\n",
    "  data = {}\n",
    "  with open(cache_path, 'w') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "with open(cache_path, 'r') as f:\n",
    "  cache = json.load(f)\n",
    "\n",
    "len(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [00:00, 1787.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "470it [01:31,  3.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE------RETRIEVE FROM PUBMED---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 43---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.48it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [03:14,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: PUBMED, VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM PUBMED---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 46---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "472it [05:42,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "473it [07:17,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "474it [09:59,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "475it [11:42,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [13:26,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [15:23, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478it [16:53, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "479it [19:35, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 45---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [22:00, 34.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481it [23:26, 39.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [25:13, 48.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [27:07, 58.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE------RETRIEVE FROM PUBMED---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 39---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "484it [29:22, 72.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE------RETRIEVE FROM PUBMED---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 34---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "485it [31:26, 83.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "486it [33:15, 89.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 36---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 2---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "487it [39:07, 153.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [39:59, 127.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 12---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "489it [42:19, 130.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 15---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "490it [44:46, 135.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 15---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "491it [47:53, 149.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED, NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM PUBMED---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 45---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 2---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [51:19, 166.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "493it [53:32, 156.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE, VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 30---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "494it [55:40, 148.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "495it [58:25, 152.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 24---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "496it [1:01:15, 158.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM PUBMED---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 45---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 1---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "497it [1:03:06, 144.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE, VECTORSTORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 46---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "498it [1:06:19, 158.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: VECTORSTORE, PUBMED---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 4---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM VECTOR STORE---\n",
      "---RETRIEVE FROM PUBMED---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 28---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "499it [1:09:45, 172.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DETERMINE SPECIALIZED SOURCES---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO SPECIALIZED SOURCES: NCBI_GENE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE SUBQUERIES---\n",
      "---FINAL SUBQUERIES NUMBER: 3---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE FROM NCBI GENE DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---INITIAL DOCUMENTS NUMBER: 11---\n",
      "---GRADE DOCUMENT (1/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (2/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (3/4)---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE DOCUMENT (4/4)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS NUMBER: 3---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [1:13:17,  8.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6251679069211469,\n",
       " 0.025192447599560224,\n",
       " 0.2227855995692924,\n",
       " 0.19491690991905436)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = list(qa_df['question'].tolist())\n",
    "expected_answers = list(qa_df['answer'].tolist())\n",
    "predicted_answers = []\n",
    "\n",
    "for index, question in tqdm(enumerate(questions)):\n",
    "  if not question in cache:\n",
    "    cache[question] = app.invoke({'question': question})['generation']\n",
    "\n",
    "  predicted_answers.append(cache[question])\n",
    "\n",
    "  with open(cache_path, 'w') as f:\n",
    "    json.dump(cache, f)\n",
    "\n",
    "cos_score = embeddings_cosine_sim_metric(expected_answers, predicted_answers)\n",
    "bleu_score = bleu_metric(expected_answers, predicted_answers)\n",
    "rogue_1_score = rogue_1_metric(expected_answers, predicted_answers)\n",
    "rogue_l_score = rogue_l_metric(expected_answers, predicted_answers)\n",
    "\n",
    "cos_score, bleu_score, rogue_1_score, rogue_l_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
