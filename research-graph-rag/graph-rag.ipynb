{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: unidecode in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (1.3.8)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (4.66.5)\n",
      "Requirement already satisfied: llm-blender in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (4.44.2)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (2.4.1)\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (0.4.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (0.6.7)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from llm-blender) (4.25.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from accelerate->llm-blender) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from accelerate->llm-blender) (5.8.0)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from accelerate->llm-blender) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from accelerate->llm-blender) (0.24.6)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from torch->llm-blender) (2024.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from dataclasses-json->llm-blender) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from dataclasses-json->llm-blender) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from transformers->llm-blender) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from transformers->llm-blender) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->llm-blender) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from jinja2->torch->llm-blender) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests->transformers->llm-blender) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests->transformers->llm-blender) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests->transformers->llm-blender) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests->transformers->llm-blender) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from sympy->torch->llm-blender) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain-core in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.2.41)\n",
      "Requirement already satisfied: langchain-community in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain_experimental in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.0.65)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.1.25)\n",
      "Requirement already satisfied: langchain-chroma in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain_mistralai in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.1.13)\n",
      "Requirement already satisfied: langgraph in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (0.2.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (0.1.118)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-openai) (1.50.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-chroma) (0.5.3)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain-chroma) (0.114.1)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain_mistralai) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain_mistralai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langchain_mistralai) (0.19.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.6.5)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.38.5)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.8)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from tokenizers<1,>=0.15.1->langchain_mistralai) (0.24.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from anyio->httpx<1,>=0.25.2->langchain_mistralai) (1.2.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.4.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2024.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.25.4)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (72.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.8.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from importlib-resources->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk numpy pandas unidecode scikit-learn tqdm llm-blender\n",
    "! pip install langchain langchain-core langchain-community langchain_experimental langchain-openai langchain-chroma langchain_mistralai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import llm_blender\n",
    "from operator import itemgetter\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings.cache import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import RetryOutputParser\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment variables\n",
    "\n",
    "You have to define the following environment variables in the `.env` file, terminal environment, or input field within this Jupyter notebook:\n",
    "1. MISTRAL_API_KEY\n",
    "2. OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables = [\n",
    "  'MISTRAL_API_KEY',\n",
    "  'OPENAI_API_KEY',\n",
    "]\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for key in env_variables:\n",
    "  value = os.getenv(key)\n",
    "\n",
    "  if value is None:\n",
    "    value = getpass(key)\n",
    "\n",
    "  os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NLTK dictionaries\n",
    "\n",
    "These dictionaries are needed for further text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ids = [\n",
    "  'punkt_tab',\n",
    "  'punkt',\n",
    "  'stopwords',\n",
    "  'wordnet',\n",
    "]\n",
    "\n",
    "for dict_id in dict_ids:\n",
    "  nltk.download(dict_id, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Define a function for text preprocessing, which is an important step before calculating any metrics. This preprocessing function will help in cleaning the text data, making it ready for further analysis. The preprocessing involves several steps:\n",
    "1. Lowercasing\n",
    "2. Stopwords removal\n",
    "3. Lemmatization\n",
    "4. Remove accents from characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess(corpus: str) -> str:\n",
    "  corpus = corpus.lower()\n",
    "  stopset = nltk.corpus.stopwords.words('english') + nltk.corpus.stopwords.words('russian') + list(string.punctuation)\n",
    "  tokens = nltk.word_tokenize(corpus)\n",
    "  tokens = [t for t in tokens if t not in stopset]\n",
    "  tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "  corpus = ' '.join(tokens)\n",
    "  corpus = unidecode(corpus)\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Initialization\n",
    "\n",
    "Here we are initializing the Llama 3 embeddings model. The `OllamaEmbeddings` class is a component of the Ollama library, a set of pre-trained language models. This model is capable of embedding corpora of any length into a 4096-dimensional vector.\n",
    "\n",
    "The use of `OllamaEmbeddings` requires the installation of a local Ollama server, which can be found at https://ollama.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model='llama3.1')\n",
    "store = LocalFileStore(\"./.embeddings_cache\")\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "  embeddings,\n",
    "  store,\n",
    "  namespace=embeddings.model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average embeddings cosine similarity metric\n",
    "\n",
    "This function calculates the average cosine similarity between expected answers and LLM predicted answers using their respective embeddings. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them:\n",
    "\n",
    "$$\n",
    "K(a, b) = \\frac{\\sum \\limits_{i=1}^n a_i b_i}{\\sqrt{\\sum \\limits_{i=1}^n a_i^2} \\cdot \\sqrt{\\sum \\limits_{i=1}^n b_i^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_cosine_sim_metric(expected_answers: list[str], predicted_answers: list[str]) -> float:\n",
    "  results = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    expected_embedding = np.array(cached_embeddings.embed_query(expected_answer))\n",
    "    predicted_embedding = np.array(cached_embeddings.embed_query(predicted_answer))\n",
    "\n",
    "    sim = cosine_similarity(\n",
    "      expected_embedding.reshape(1, -1),\n",
    "      predicted_embedding.reshape(1, -1),\n",
    "    )[0][0]\n",
    "\n",
    "    results.append(sim)\n",
    "\n",
    "  return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothie_f = nltk.translate.bleu_score.SmoothingFunction().method4\n",
    "\n",
    "def bleu_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    predicted_tokens = nltk.word_tokenize(predicted_answer)\n",
    "    expected_tokens = [nltk.word_tokenize(expected_answer)]\n",
    "\n",
    "    score = nltk.translate.bleu_score.sentence_bleu(\n",
    "      expected_tokens,\n",
    "      predicted_tokens,\n",
    "      smoothing_function=smoothie_f,\n",
    "    )\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogue_1_scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "def rogue_1_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    result = rogue_1_scorer.score(expected_answer, predicted_answer)\n",
    "\n",
    "    scores.append(result['rouge1'])\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogue_l_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def rogue_l_metric(expected_answers, predicted_answers):\n",
    "  scores = []\n",
    "\n",
    "  for expected_answer, predicted_answer in zip(expected_answers, predicted_answers):\n",
    "    expected_answer = preprocess(expected_answer)\n",
    "    predicted_answer = preprocess(predicted_answer)\n",
    "\n",
    "    result = rogue_l_scorer.score(expected_answer, predicted_answer)\n",
    "\n",
    "    scores.append(result['rougeL'])\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dir = Path('./docs')\n",
    "docs_cache_dir = Path('./.docs_cache')\n",
    "raw_docs_pkl_path = docs_cache_dir / 'parsed_docs_cache.pkl'\n",
    "\n",
    "docs = None\n",
    "\n",
    "if os.path.exists(raw_docs_pkl_path):\n",
    "  with open(raw_docs_pkl_path, 'rb') as f:\n",
    "    docs = pickle.load(f)\n",
    "else:\n",
    "  docs = []\n",
    "  for file in docs_dir.iterdir():\n",
    "    docs.extend(PDFMinerLoader(file).load())\n",
    "\n",
    "  with open(raw_docs_pkl_path, 'wb') as f:\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17443"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitted_docs_pkl_path = docs_cache_dir / 'splitted_docs_cache.pkl'\n",
    "\n",
    "if os.path.exists(splitted_docs_pkl_path):\n",
    "  with open(splitted_docs_pkl_path, 'rb') as f:\n",
    "    splitted_docs = pickle.load(f)\n",
    "else:\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=750,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "  )\n",
    "  splitted_docs = text_splitter.create_documents([doc.page_content for doc in docs])\n",
    "\n",
    "  with open(splitted_docs_pkl_path, 'wb') as f:\n",
    "    pickle.dump(splitted_docs, f)\n",
    "\n",
    "len(splitted_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "  embedding_function=cached_embeddings,\n",
    "  persist_directory='./chroma_db'\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define JSON extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response):\n",
    "  json_pattern = r'\\{.*?\\}'\n",
    "  match = re.search(json_pattern, response, re.DOTALL)\n",
    "\n",
    "  if match:\n",
    "    return match.group().strip()\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model='llama3.1', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_source='websearch'\n",
      "data_source='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "  data_source: Literal['vectorstore', 'websearch'] = Field(\n",
    "    description='Given a user question choose to route it to web search or a vectorstore.',\n",
    "  )\n",
    "\n",
    "route_parser = PydanticOutputParser(pydantic_object=RouteQuery)\n",
    "route_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=route_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "route_template = \"\"\"\n",
    "You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to neurobiology and medicine.\n",
    "Use the vectorstore for questions on these topics. For all else, use web-search.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "route_prompt = PromptTemplate(\n",
    "  template=route_template,\n",
    "  input_variables=['question'],\n",
    "  partial_variables={'format_instructions': route_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "question_router = RunnableParallel(\n",
    "  completion=route_prompt | llm | extract_json, prompt_value=route_prompt\n",
    ") | RunnableLambda(lambda x: route_retry_parser.parse_with_prompt(**x))\n",
    "print(question_router.invoke({'question': 'Who will the Bears draft first in the NFL draft?'}))\n",
    "print(question_router.invoke({'question': 'What is the order of the cranial nerves?'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade documents chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeDocuments(binary_score='yes')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "  binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "docs_grade_parser = PydanticOutputParser(pydantic_object=GradeDocuments)\n",
    "docs_grade_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=docs_grade_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "docs_grade_template = \"\"\"\n",
    "You are a grader assessing relevance of a retrieved document to a user question.\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Retrieved document:\n",
    "{document}\n",
    "\"\"\"\n",
    "docs_grade_prompt = PromptTemplate(\n",
    "  template=docs_grade_template,\n",
    "  input_variables=['document', 'question'],\n",
    "  partial_variables={'format_instructions': docs_grade_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "docs_grade_grader = RunnableParallel(\n",
    "  completion=docs_grade_prompt | llm | extract_json, prompt_value=docs_grade_prompt\n",
    ") | RunnableLambda(lambda x: docs_grade_retry_parser.parse_with_prompt(**x))\n",
    "docs_grade_grader.invoke({'question': 'What is the color of the sky?', 'document': 'The color of the sky is blue'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucinations chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "  binary_score: str = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
    "\n",
    "hallucination_parser = PydanticOutputParser(pydantic_object=GradeHallucinations)\n",
    "hallucination_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=hallucination_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "hallucination_template = \"\"\"\n",
    "You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Set of facts:\n",
    "{documents}\n",
    "\n",
    "LLM generation:\n",
    "{generation}\n",
    "\"\"\"\n",
    "hallucination_prompt = PromptTemplate(\n",
    "  template=hallucination_template,\n",
    "  input_variables=['question', 'generation'],\n",
    "  partial_variables={'format_instructions': hallucination_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "hallucination_grader = RunnableParallel(\n",
    "  completion=hallucination_prompt | llm | extract_json, prompt_value=hallucination_prompt\n",
    ") | RunnableLambda(lambda x: hallucination_retry_parser.parse_with_prompt(**x))\n",
    "print(hallucination_grader.invoke({'documents': ['Sky is blue'], 'generation': 'The color of the sky is blue'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer grade chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "  binary_score: str = Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "\n",
    "grade_parser = PydanticOutputParser(pydantic_object=GradeAnswer)\n",
    "grade_retry_parser = RetryOutputParser.from_llm(\n",
    "  parser=grade_parser,\n",
    "  llm=llm,\n",
    "  max_retries=3,\n",
    ")\n",
    "\n",
    "grade_template = \"\"\"\n",
    "You are a grader assessing whether an answer addresses / resolves a question. \\n\n",
    "Give a binary score 'yes' or 'no'. 'yes' means that the answer resolves the question.\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "LLM generation:\n",
    "{generation}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "grade_prompt = PromptTemplate(\n",
    "  template=grade_template,\n",
    "  input_variables=['question', 'generation'],\n",
    "  partial_variables={'format_instructions': grade_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "answer_grader = RunnableParallel(\n",
    "  completion=grade_prompt | llm | extract_json, prompt_value=grade_prompt\n",
    ") | RunnableLambda(lambda x: grade_retry_parser.parse_with_prompt(**x))\n",
    "print(answer_grader.invoke({\"question\": \"What is the order of the cranial nerves?\", 'generation': 'I do not know.'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a scientific paper-style passage answering the question:\\n\\n**Title:** The Cranial Nerve Plexus: A Review of the Anatomical and Neurological Organization\\n\\n**Abstract:**\\n\\nThe cranial nerves, a complex network of 12 pairs of nerves that arise from the brainstem, play a crucial role in regulating various physiological functions. Understanding their organization is essential for appreciating the intricate relationships between the central nervous system and the peripheral nervous system. This review aims to provide an overview of the order of the cranial nerves, highlighting their anatomical and neurological characteristics.\\n\\n**Introduction:**\\n\\nThe cranial nerves are a group of nerves that emerge from the brainstem, which includes the midbrain, pons, and medulla oblongata. These nerves are responsible for controlling various functions such as sensation, movement, and autonomic regulation. The order of the cranial nerves is a fundamental concept in neuroanatomy, and their correct identification is essential for clinical diagnosis and treatment.\\n\\n**The Order of the Cranial Nerves:**\\n\\nThe 12 pairs of cranial nerves are listed in the following order:\\n\\n1. **Olfactory nerve (I)**: The first cranial nerve to develop, responsible for transmitting sensory information from the olfactory epithelium.\\n2. **Optic nerve (II)**: A paired nerve that transmits visual information from the retina to the brain.\\n3. **Occulomotor nerve (III)**: A large nerve that controls eye movement and pupillary constriction.\\n4. **Trochlear nerve (IV)**: The thinnest cranial nerve, responsible for controlling superior oblique muscle function.\\n5. **Trigeminal nerve (V)**: A complex nerve with three branches (ophthalmic, maxillary, and mandibular) that regulate facial sensation and motor functions.\\n6. **Abducens nerve (VI)**: A small nerve that controls lateral rectus muscle function.\\n7. **Facial nerve (VII)**: A mixed nerve responsible for controlling facial expression, taste, and hearing.\\n8. **Vestibulocochlear nerve (VIII)**: A paired nerve that transmits auditory and vestibular information from the inner ear to the brain.\\n9. **Glossopharyngeal nerve (IX)**: A complex nerve with multiple branches that regulate swallowing, taste, and motor functions.\\n10. **Vagus nerve (X)**: A mixed nerve responsible for controlling various visceral functions such as heart rate, digestion, and respiration.\\n11. **Spinal accessory nerve (XI)**: A paired nerve that regulates sternocleidomastoid and trapezius muscle function.\\n12. **Hypoglossal nerve (XII)**: The smallest cranial nerve, responsible for controlling tongue movement.\\n\\n**Conclusion:**\\n\\nIn conclusion, the order of the cranial nerves is a fundamental concept in neuroanatomy that has significant implications for clinical diagnosis and treatment. Understanding the anatomical and neurological characteristics of each cranial nerve is essential for appreciating their complex relationships with the central nervous system and peripheral nervous system.\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "hyde_template = \"\"\"\n",
    "Please write a scientific paper passage to answer the question\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Passage:\n",
    "\"\"\"\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_template)\n",
    "hyde_chain = hyde_prompt | llm | StrOutputParser()\n",
    "\n",
    "hyde_chain.invoke({\"question\": 'What is the order of the cranial nerves ?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The step-back query would be:\\n\\n\"What are the main categories or classifications of the human nervous system?\"\\n\\nThis query takes a step back from the original question, which focuses on a specific aspect (the order of cranial nerves), and instead asks for more general information about the broader category (the human nervous system). This can help retrieve relevant background information that might include details about the structure and organization of the nervous system, including the classification of cranial nerves.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "step_back_template = \"\"\"\n",
    "You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "Step-back query:\n",
    "\"\"\"\n",
    "step_back_prompt = ChatPromptTemplate.from_template(step_back_template)\n",
    "step_back_chain = step_back_prompt | llm | StrOutputParser()\n",
    "\n",
    "step_back_chain.invoke({\"question\": 'What is the order of the cranial nerves ?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a rewritten version of the query that\\'s more specific, detailed, and likely to retrieve relevant information:\\n\\n\"What is the anatomical order and classification of the 12 pairs of cranial nerves in humans, including their respective functions, origins, and pathways within the brain and spinal cord?\"\\n\\nThis revised query adds specificity by:\\n\\n* Specifying the number of cranial nerves (12 pairs)\\n* Asking for anatomical order and classification\\n* Requesting information on functions, origins, and pathways\\n* Clarifying that the context is human anatomy\\n\\nBy making these changes, the rewritten query should retrieve more relevant and detailed information from a RAG system.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rewrite_query_template = \"\"\"\n",
    "You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system.\n",
    "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
    "\n",
    "Original query: {question}\n",
    "\n",
    "Rewritten query:\n",
    "\"\"\"\n",
    "rewrite_query_prompt = ChatPromptTemplate.from_template(rewrite_query_template)\n",
    "rewrite_query_chain = rewrite_query_prompt | llm | StrOutputParser()\n",
    "\n",
    "rewrite_query_chain.invoke({\"question\": 'What is the order of the cranial nerves ?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No ranker config provided, no ranker loaded, please load ranker first through load_ranker()\n",
      "WARNING:root:No fuser config provided, no fuser loaded, please load fuser first through load_fuser()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ranker from  /Users/vladimirskvortsov/.cache/huggingface/hub/llm-blender/PairRM\n"
     ]
    }
   ],
   "source": [
    "blender = llm_blender.Blender()\n",
    "blender.loadranker('llm-blender/PairRM', device='mps')\n",
    "blender.loadfuser('llm-blender/gen_fuser_3b', device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The order of the cranial nerves is as follows: I. Olfactory II. Optic III. Oculomotor IV. Trochlear V. Trigeminal VI. Abducens VII. Facial VIII. Auditory (or vestibulocochlear) nerve IX. Glossopharyngeal X. Vagus XI. Spinal accessory XII. Hypoglossal.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "llama_llm = Ollama(model='llama3.1', temperature=0)\n",
    "mistral_llm = ChatMistralAI(model='mistral-large-latest', temperature=0)\n",
    "gpt_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "llama_chain = prompt | llama_llm | StrOutputParser()\n",
    "mistral_chain = prompt | mistral_llm | StrOutputParser()\n",
    "gpt_chain = prompt | gpt_llm | StrOutputParser()\n",
    "\n",
    "def fuse_generations(dict):\n",
    "  question = dict['question']\n",
    "\n",
    "  llama_res = dict['llama_res']\n",
    "  mistral_res = dict['mistral_res']\n",
    "  gpt_res = dict['gpt_res']\n",
    "  answers = [llama_res, mistral_res, gpt_res]\n",
    "\n",
    "  fuse_generations, ranks = blender.rank_and_fuse(\n",
    "    [question],\n",
    "    [answers],\n",
    "    instructions=[''],\n",
    "    return_scores=False,\n",
    "    batch_size=2,\n",
    "    top_k=3\n",
    "  )\n",
    "  return fuse_generations[0]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "  {\n",
    "    'llama_res': llama_chain,\n",
    "    'mistral_res': mistral_chain,\n",
    "    'gpt_res': gpt_chain,\n",
    "    'question': itemgetter('question')\n",
    "  }\n",
    "  | RunnableLambda(fuse_generations)\n",
    ")\n",
    "\n",
    "rag_chain.invoke({\"context\": '', \"question\": 'What is the order of the cranial nerves ?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web search chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "web_search_tool = TavilySearchResults(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "  question: str\n",
    "  step_back_query: str\n",
    "  rewritten_query: str\n",
    "  generated_docs: str\n",
    "  documents: List[str]\n",
    "  web_search: str\n",
    "  generation: str\n",
    "  generations_num: int\n",
    "\n",
    "def route_question(state):\n",
    "  print('---ROUTE QUESTION---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  source = question_router.invoke({'question': question})\n",
    "\n",
    "  if source.data_source == 'websearch':\n",
    "    print('---ROUTE QUESTION TO WEB SEARCH---')\n",
    "    return 'websearch'\n",
    "  elif source.data_source == 'vectorstore':\n",
    "    print('---ROUTE QUESTION TO VECTOR STORE---')\n",
    "    return 'vectorstore'\n",
    "\n",
    "def generate_step_back_query(state):\n",
    "  print('---GENERATE STEP-BACK QUERY---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  step_back_query = step_back_chain.invoke({'question': question})\n",
    "\n",
    "  return {'question': question, 'step_back_query': step_back_query}\n",
    "\n",
    "def generate_rewritten_query(state):\n",
    "  print('---GENERATE REWRITTEN QUERY---')\n",
    "\n",
    "  question = state['question']\n",
    "\n",
    "  rewritten_query = rewrite_query_chain.invoke({'question': question})\n",
    "\n",
    "  return {'question': question, 'rewritten_query': rewritten_query}\n",
    "\n",
    "def generate_hyde_docs(state):\n",
    "  print('---GENERATE HYDE DOCUMENTS---')\n",
    "\n",
    "  question = state['question']\n",
    "  step_back_query = state['step_back_query']\n",
    "  rewritten_query = state['rewritten_query']\n",
    "\n",
    "  queries = [question, step_back_query, rewritten_query]\n",
    "  generated_docs = []\n",
    "\n",
    "  for query in queries:\n",
    "    generated_doc = hyde_chain.invoke({'question': query})\n",
    "    generated_docs.append(generated_doc)\n",
    "\n",
    "  return {'question': question, 'generated_docs': generated_docs}\n",
    "\n",
    "def retrieve(state):\n",
    "  print('---RETRIEVE---')\n",
    "\n",
    "  question = state['question']\n",
    "  generated_docs = state['generated_docs']\n",
    "\n",
    "  docs = []\n",
    "\n",
    "  for generated_doc in generated_docs:\n",
    "    docs.extend(retriever.invoke(generated_doc))\n",
    "\n",
    "  unique_docs = []\n",
    "  seen_contents = set()\n",
    "\n",
    "  for doc in docs:\n",
    "    if doc.page_content in seen_contents:\n",
    "      continue\n",
    "\n",
    "    unique_docs.append(doc)\n",
    "    seen_contents.add(doc.page_content)\n",
    "\n",
    "\n",
    "  return {'question': question, 'documents': unique_docs}\n",
    "\n",
    "def grade_documents(state):\n",
    "  print('---CHECK DOCUMENT RELEVANCE TO QUESTION---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state['documents']\n",
    "\n",
    "  # Score each doc\n",
    "  filtered_docs = []\n",
    "  web_search = 'No'\n",
    "  for index, d in enumerate(documents):\n",
    "    print(f'---GRADE DOCUMENT ({index + 1}/{len(documents)})---')\n",
    "    try:\n",
    "      score = docs_grade_grader.invoke({'question': question, 'document': d.page_content})\n",
    "      grade = score.binary_score\n",
    "    except:\n",
    "      grade = 'No'\n",
    "    # Document relevant\n",
    "    if grade.lower() == 'yes':\n",
    "      print('---GRADE: DOCUMENT RELEVANT---')\n",
    "      filtered_docs.append(d)\n",
    "    # Document not relevant\n",
    "    else:\n",
    "      print('---GRADE: DOCUMENT NOT RELEVANT---')\n",
    "      # We do not include the document in filtered_docs\n",
    "      # We set a flag to indicate that we want to run web search\n",
    "      web_search = 'Yes'\n",
    "      continue\n",
    "\n",
    "  print(f'---FINAL DOCUMENTS COUNT: {len(filtered_docs)}---')\n",
    "\n",
    "  return {\n",
    "    'question': question,\n",
    "    'documents': filtered_docs,\n",
    "    'web_search': web_search,\n",
    "  }\n",
    "\n",
    "def decide_to_generate(state):\n",
    "  print('---ASSESS GRADED DOCUMENTS---')\n",
    "\n",
    "  web_search = state['web_search']\n",
    "\n",
    "  if web_search == 'Yes':\n",
    "    # Some documents have been filtered check_relevance\n",
    "    # We will re-generate a new query\n",
    "    print('---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---')\n",
    "    return 'websearch'\n",
    "  else:\n",
    "    # We have relevant documents, so generate answer\n",
    "    print('---DECISION: GENERATE---')\n",
    "    return 'generate'\n",
    "\n",
    "def web_search(state):\n",
    "  print('---WEB SEARCH---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state.get('documents')\n",
    "\n",
    "  try:\n",
    "    docs = web_search_tool.invoke({'query': question})\n",
    "    web_results = '\\n'.join([d['content'] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "      documents.append(web_results)\n",
    "    else:\n",
    "      documents = [web_results]\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  return {\n",
    "    'question': question,\n",
    "    'documents': documents,\n",
    "  }\n",
    "\n",
    "def generate(state):\n",
    "  print('---GENERATE---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state['documents']\n",
    "  generations_num = state.get('generations_num', 0)\n",
    "\n",
    "  # RAG generation\n",
    "  generation = rag_chain.invoke({'context': documents, 'question': question})\n",
    "  return {\n",
    "    'question': question,\n",
    "    'documents': documents,\n",
    "    'generation': generation,\n",
    "    'generations_num': generations_num + 1,\n",
    "  }\n",
    "\n",
    "def grade_generation(state):\n",
    "  print('---CHECK HALLUCINATIONS---')\n",
    "\n",
    "  question = state['question']\n",
    "  documents = state['documents']\n",
    "  generation = state['generation']\n",
    "  generations_num = state['generations_num']\n",
    "\n",
    "  if generations_num >= 2:\n",
    "    return 'useful'\n",
    "\n",
    "  try:\n",
    "    score = hallucination_grader.invoke({'documents': documents, 'generation': generation})\n",
    "    grade = score.binary_score\n",
    "  except:\n",
    "    grade = 'no'\n",
    "\n",
    "  # Check hallucination\n",
    "  if grade == 'yes':\n",
    "    print('---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---')\n",
    "    # Check question-answering\n",
    "    print('---GRADE GENERATION vs QUESTION---')\n",
    "    try:\n",
    "      score = answer_grader.invoke({'question': question,'generation': generation})\n",
    "      grade = score.binary_score\n",
    "    except:\n",
    "      grade = 'no'\n",
    "\n",
    "    if grade == 'yes':\n",
    "      print('---DECISION: GENERATION ADDRESSES QUESTION---')\n",
    "      return 'useful'\n",
    "    else:\n",
    "      print('---DECISION: GENERATION DOES NOT ADDRESS QUESTION---')\n",
    "      return 'not useful'\n",
    "  else:\n",
    "    print('---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---')\n",
    "    return 'not supported'\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node('generate_step_back_query', generate_step_back_query)\n",
    "workflow.add_node('generate_rewritten_query', generate_rewritten_query)\n",
    "workflow.add_node('generate_hyde_docs', generate_hyde_docs)\n",
    "workflow.add_node('retrieve', retrieve)\n",
    "workflow.add_node('websearch', web_search)\n",
    "workflow.add_node('generate', generate)\n",
    "workflow.add_node('grade_documents', grade_documents)\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "  route_question,\n",
    "  {\n",
    "    'websearch': 'websearch',\n",
    "    'vectorstore': 'generate_step_back_query',\n",
    "  },\n",
    ")\n",
    "workflow.add_edge('generate_step_back_query', 'generate_rewritten_query')\n",
    "workflow.add_edge('generate_rewritten_query', 'generate_hyde_docs')\n",
    "workflow.add_edge('generate_hyde_docs', 'retrieve')\n",
    "workflow.add_edge('retrieve', 'grade_documents')\n",
    "workflow.add_conditional_edges(\n",
    "  'grade_documents',\n",
    "  decide_to_generate,\n",
    "  {\n",
    "    'websearch': 'websearch',\n",
    "    'generate': 'generate',\n",
    "  },\n",
    ")\n",
    "workflow.add_edge('websearch', 'generate')\n",
    "workflow.add_conditional_edges(\n",
    "  'generate',\n",
    "  grade_generation,\n",
    "  {\n",
    "    'not supported': 'generate',\n",
    "    'useful': END,\n",
    "    'not useful': 'websearch',\n",
    "  },\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO VECTOR STORE---\n",
      "---GENERATE STEP-BACK QUERY---\n",
      "---GENERATE REWRITTEN QUERY---\n",
      "---GENERATE HYDE DOCUMENTS---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE DOCUMENT (1/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (2/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (3/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (4/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (5/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (6/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (7/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (8/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (9/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE DOCUMENT (10/10)---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---FINAL DOCUMENTS COUNT: 0---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking candidates: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Fusing candidates: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the order of the cranial nerves?',\n",
       " 'step_back_query': 'The step-back query would be:\\n\\n\"What are the main categories or classifications of the human nervous system?\"\\n\\nThis query takes a step back from the original question, which focuses on a specific aspect (the order of cranial nerves), and instead asks for more general information about the broader category (the human nervous system). This can help retrieve relevant background information that might include details about the structure and organization of the nervous system, including the classification of cranial nerves.',\n",
       " 'rewritten_query': 'Here\\'s a rewritten version of the query that\\'s more specific, detailed, and likely to retrieve relevant information:\\n\\n\"What is the correct anatomical order of the 12 pairs of cranial nerves, including their names (I-XII), functions, and any notable characteristics or associations with specific brain regions or structures?\"\\n\\nThis revised query adds specificity by:\\n\\n* Specifying the number of cranial nerves (12)\\n* Including their names (I-XII) for clarity\\n* Mentioning their functions to provide context\\n* Asking about notable characteristics or associations to encourage retrieval of relevant information\\n\\nBy making these changes, the rewritten query is more likely to retrieve accurate and detailed information from a RAG system.',\n",
       " 'generated_docs': [\"Here's a scientific paper-style passage answering the question:\\n\\n**Title:** The Cranial Nerve Order: A Review and Classification\\n\\n**Abstract:**\\nThe cranial nerves are a complex group of 12 pairs of nerves that arise directly from the brain, playing crucial roles in various physiological functions. Despite their importance, there is often confusion regarding the order in which these nerves are typically listed. This review aims to clarify the standard classification system used to organize the cranial nerves.\\n\\n**Introduction:**\\nThe cranial nerves are a vital component of the nervous system, responsible for controlling various bodily functions such as sensation, movement, and autonomic regulation. Each nerve has a distinct function and is named according to its primary role or location in the body. However, the order in which these nerves are listed can be inconsistent across different sources.\\n\\n**Methods:**\\nTo establish a standardized classification system, we consulted multiple anatomical texts and neuroscientific resources. We identified the 12 pairs of cranial nerves and categorized them based on their functional characteristics and embryological origins.\\n\\n**Results:**\\nThe standard order of the cranial nerves is as follows:\\n\\n1. **Olfactory nerve (I)**: responsible for transmitting sensory information related to smell.\\n2. **Optic nerve (II)**: transmits visual information from the retina to the brain.\\n3. **Occulomotor nerve (III)**: controls eye movement and pupil constriction.\\n4. **Trochlear nerve (IV)**: innervates the superior oblique muscle, responsible for rotational movements of the eye.\\n5. **Trigeminal nerve (V)**: has three branches that provide sensory information from the face and motor control over muscles involved in mastication.\\n6. **Abducens nerve (VI)**: controls lateral movement of the eye.\\n7. **Facial nerve (VII)**: responsible for transmitting taste information, controlling facial expressions, and regulating salivation.\\n8. **Auditory (vestibulocochlear) nerve (VIII)**: transmits auditory and vestibular information from the inner ear to the brain.\\n9. **Glossopharyngeal nerve (IX)**: provides sensory information from the pharynx and regulates swallowing, as well as controlling salivation and taste.\\n10. **Vagus nerve (X)**: has a wide range of functions, including regulating autonomic responses, transmitting sensory information, and controlling various visceral organs.\\n11. **Spinal accessory nerve (XI)**: innervates muscles involved in shoulder movement and neck rotation.\\n12. **Hypoglossal nerve (XII)**: controls tongue movements.\\n\\n**Conclusion:**\\nThe cranial nerves are a complex group of nerves that play essential roles in human physiology. By establishing a standardized classification system, we have clarified the order in which these nerves are typically listed. This review provides a comprehensive overview of the cranial nerves and their functions, serving as a valuable resource for neuroscientists, anatomists, and medical professionals alike.\",\n",
       "  'Here is a scientific paper passage to answer the question:\\n\\n**The Human Nervous System: A Comprehensive Overview**\\n\\nThe human nervous system (HNS) is a complex network of specialized cells, tissues, and organs that facilitate communication between different parts of the body. It can be broadly classified into two main categories: the central nervous system (CNS) and the peripheral nervous system (PNS).\\n\\nThe CNS consists of the brain and spinal cord, which are responsible for processing information, controlling voluntary movements, and regulating various bodily functions such as heart rate, blood pressure, and respiration. The PNS, on the other hand, comprises nerves that arise from the CNS and extend to various parts of the body, including sensory receptors, muscles, and glands.\\n\\nWithin the PNS, there are two subcategories: the somatic nervous system (SNS) and the autonomic nervous system (ANS). The SNS is responsible for transmitting information related to voluntary movements, such as walking, talking, and writing. In contrast, the ANS regulates involuntary functions, including heart rate, digestion, and respiration.\\n\\nFurthermore, the cranial nerves, which arise from the brain, can be classified into 12 pairs based on their function and location. These include the olfactory (I) and optic (II) nerves, which are responsible for transmitting sensory information related to smell and vision, respectively. The remaining 10 pairs of cranial nerves (III-XII) control various functions such as swallowing, hearing, taste, and facial expressions.\\n\\nIn conclusion, the human nervous system is a highly organized and complex entity that can be broadly classified into two main categories: the CNS and PNS. Within the PNS, there are two subcategories: SNS and ANS. Understanding these classifications provides a fundamental framework for appreciating the structure and function of the HNS, including the organization and classification of cranial nerves.',\n",
       "  \"Here's a scientific paper passage that answers the question:\\n\\n**The Anatomical Order and Functions of the 12 Pairs of Cranial Nerves**\\n\\nThe cranial nerves are a group of 12 pairs of nerves that arise directly from the brain, playing crucial roles in various physiological processes. The correct anatomical order of these nerves is as follows: I. Olfactory nerve, II. Optic nerve, III. Occulomotor nerve, IV. Trochlear nerve, V. Trigeminal nerve, VI. Abducens nerve, VII. Facial nerve, VIII. Auditory (vestibulocochlear) nerve, IX. Glossopharyngeal nerve, X. Vagus nerve, XI. Spinal accessory nerve, and XII. Hypoglossal nerve.\\n\\nEach cranial nerve has distinct functions, which are summarized below:\\n\\n* I. Olfactory nerve: responsible for transmitting sensory information from the olfactory receptors to the brain.\\n* II. Optic nerve: transmits visual information from the retina to the brain.\\n* III. Occulomotor nerve: controls eye movement and pupil constriction.\\n* IV. Trochlear nerve: innervates the superior oblique muscle, responsible for rotational movements of the eyeball.\\n* V. Trigeminal nerve: provides sensory input from the face and motor output to the muscles of mastication (chewing).\\n* VI. Abducens nerve: controls lateral eye movement through its innervation of the lateral rectus muscle.\\n* VII. Facial nerve: responsible for facial expression, taste sensation, and transmission of auditory information.\\n* VIII. Auditory (vestibulocochlear) nerve: transmits sound and balance information from the inner ear to the brain.\\n* IX. Glossopharyngeal nerve: provides sensory input from the pharynx and motor output to the stylopharyngeus muscle, involved in swallowing.\\n* X. Vagus nerve: innervates various organs, including the larynx, esophagus, and heart, controlling functions such as respiration and digestion.\\n* XI. Spinal accessory nerve: provides motor input to the sternocleidomastoid and trapezius muscles, involved in neck and shoulder movements.\\n* XII. Hypoglossal nerve: controls tongue movement through its innervation of the extrinsic and intrinsic muscles.\\n\\nNotable characteristics or associations include:\\n\\n* The olfactory nerve is unique among cranial nerves as it arises from the forebrain rather than the brainstem.\\n* The trigeminal nerve has three distinct branches (ophthalmic, maxillary, and mandibular) that provide sensory input to different regions of the face.\\n* The vagus nerve has a wide distribution, innervating various organs in the thorax and abdomen.\\n* The spinal accessory nerve is the only cranial nerve that arises from the upper cervical cord rather than the brainstem.\\n\\nIn conclusion, each cranial nerve plays a distinct role in maintaining homeostasis and facilitating communication between the central nervous system and peripheral structures. Understanding their anatomical order, functions, and associations with specific brain regions or structures is essential for appreciating the complex neural mechanisms that govern human physiology.\"],\n",
       " 'documents': [Document(page_content='Anatomy. Cranial nerves are the 12 nerves of the peripheral nervous system that emerge from the foramina and fissures of the cranium.Their numerical order (1-12) is determined by their skull exit location (rostral to caudal). All cranial nerves originate from nuclei in the brain.Two originate from the forebrain (Olfactory and Optic), one has a nucleus in the spinal cord (Accessory) while the ...\\nThe numbering of the cranial nerves is based on the order in which they emerge from the brain and brainstem, from front to back. [2] The terminal nerves (0), olfactory nerves (I) and optic nerves (II) emerge from the cerebrum, and the remaining ten pairs arise from the brainstem, which is the lower part of the brain. [3]\\nThe cranial nerves are numbered by their location on the brainstem (superior to inferior, then medial to lateral) and the order of their exit from the cranium (anterior to posterior) (Figures 1 & 2). By Patrick J. Lynch, medical illustrator derivative work: Beao derivative work: Dwstultz [CC BY 2.5], via Wikimedia Commons\\nCranial nerve mnemonics are memory devices to help you remember the names of the nerves in order of one through 12. They can also help you remember whether the nerves are sensory, motor or both. Cranial nerve mnemonics to remember the names of the nerves in order include:\\nOlfactory nerve (CN I) CN I is the olfactory nerve. Optic nerve (CN II) CN II is the optic nerve. CN III is the oculomotor nerve. It provides general somatic efferent and general visceral efferent fibres to the extraocular muscles and pupillary constrictor muscles respectively. Trigeminal nerve (CN V) CN V is the trigeminal nerve. Abducens nerve (CN VI)\\xa0 CN VI is the abducens nerve. Facial nerve (CN VII) CN VII is the facial nerve. Vestibulocochlear nerve (CN VIII) Glossopharyngeal nerve (CN IX) CN IX is the glossopharyngeal nerve. Vagus nerve (CN X) CN X is the vagus nerve. Hypoglossal nerve (CN XII) CN XII is the hypoglossal nerve. It provides general somatic efferent fibres for controlling tongue muscles. Nerve')],\n",
       " 'web_search': 'Yes',\n",
       " 'generation': 'The order of the cranial nerves is as follows: Olfactory (I), Optic (II), Oculomotor (III), Trochlear (IV), Trigeminal (V), Abducens (VI), Facial (VII), Vestibulocochlear (VIII), Glossopharyngeal (IX), Vagus (X), Accessory (XI), and Hypoglossal (XII).',\n",
       " 'generations_num': 1}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\": 'What is the order of the cranial nerves?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the afferent cranial nerve nuclei?</td>\n",
       "      <td>Trigeminal sensory nucleus- fibres carry gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the order of the cranial nerves ?</td>\n",
       "      <td>1-olfactory\\n2-optic\\n3-oculomotor\\n4-trochlea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the efferent cranial nerve nuclei?</td>\n",
       "      <td>Edinger-westphal nucleus\\nOculomotor nucleus\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which nuclei share the embryo logical origin -...</td>\n",
       "      <td>Oculomotor nucleus Trochlear nucleus Abducens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which nuclei share the embryo logical origin- ...</td>\n",
       "      <td>Trigeminal motor nucleus Facial motor nucleus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>What is the purpose of gephyrin in the glycine...</td>\n",
       "      <td>Involved in anchoring the receptor to a specif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>What is the glycine receptor involved in ?</td>\n",
       "      <td>Reflex response\\nCauses reciprocal inhibition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>What happens in hyperperplexia ?</td>\n",
       "      <td>It’s an exaggerated reflex Often caused by a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>What is hyperperplexia treated with ?</td>\n",
       "      <td>Benzodiazepine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>What increases glycine release ?</td>\n",
       "      <td>Tetanus toxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0           What are the afferent cranial nerve nuclei?   \n",
       "1             What is the order of the cranial nerves ?   \n",
       "2           What are the efferent cranial nerve nuclei?   \n",
       "3     Which nuclei share the embryo logical origin -...   \n",
       "4     Which nuclei share the embryo logical origin- ...   \n",
       "...                                                 ...   \n",
       "1047  What is the purpose of gephyrin in the glycine...   \n",
       "1048         What is the glycine receptor involved in ?   \n",
       "1049                   What happens in hyperperplexia ?   \n",
       "1050              What is hyperperplexia treated with ?   \n",
       "1051                   What increases glycine release ?   \n",
       "\n",
       "                                                 answer  \n",
       "0     Trigeminal sensory nucleus- fibres carry gener...  \n",
       "1     1-olfactory\\n2-optic\\n3-oculomotor\\n4-trochlea...  \n",
       "2     Edinger-westphal nucleus\\nOculomotor nucleus\\n...  \n",
       "3     Oculomotor nucleus Trochlear nucleus Abducens ...  \n",
       "4     Trigeminal motor nucleus Facial motor nucleus ...  \n",
       "...                                                 ...  \n",
       "1047  Involved in anchoring the receptor to a specif...  \n",
       "1048  Reflex response\\nCauses reciprocal inhibition ...  \n",
       "1049  It’s an exaggerated reflex Often caused by a m...  \n",
       "1050                                     Benzodiazepine  \n",
       "1051                                      Tetanus toxin  \n",
       "\n",
       "[1052 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_csv('brainscape.csv')\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cached RAGs responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_path = Path('cache.json')\n",
    "\n",
    "if not os.path.exists(cache_path):\n",
    "  data = {}\n",
    "  with open(cache_path, 'w') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "with open(cache_path, 'r') as f:\n",
    "  cache = json.load(f)\n",
    "\n",
    "len(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1052it [00:01, 732.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cache_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(cache, f)\n\u001b[0;32m---> 14\u001b[0m cos_score \u001b[38;5;241m=\u001b[39m \u001b[43membeddings_cosine_sim_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_answers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_answers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m bleu_metric(expected_answers, predicted_answers)\n\u001b[1;32m     16\u001b[0m rogue_1_score \u001b[38;5;241m=\u001b[39m rogue_1_metric(expected_answers, predicted_answers)\n",
      "Cell \u001b[0;32mIn[81], line 8\u001b[0m, in \u001b[0;36membeddings_cosine_sim_metric\u001b[0;34m(expected_answers, predicted_answers)\u001b[0m\n\u001b[1;32m      5\u001b[0m expected_answer \u001b[38;5;241m=\u001b[39m preprocess(expected_answer)\n\u001b[1;32m      6\u001b[0m predicted_answer \u001b[38;5;241m=\u001b[39m preprocess(predicted_answer)\n\u001b[0;32m----> 8\u001b[0m expected_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcached_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_answer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m predicted_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(cached_embeddings\u001b[38;5;241m.\u001b[39membed_query(predicted_answer))\n\u001b[1;32m     11\u001b[0m sim \u001b[38;5;241m=\u001b[39m cosine_similarity(\n\u001b[1;32m     12\u001b[0m   expected_embedding\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     13\u001b[0m   predicted_embedding\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m )[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/langchain/embeddings/cache.py:194\u001b[0m, in \u001b[0;36mCacheBackedEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed query text.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03mBy default, this method does not cache queries. To enable caching, set the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    The embedding for the given text.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_embedding_store:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munderlying_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m (cached,) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_embedding_store\u001b[38;5;241m.\u001b[39mmget([text])\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:222\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed a query using a Ollama deployed embedding model.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m instruction_pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minstruction_pair\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:197\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_emb_response(prompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:197\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/langchain_community/embeddings/ollama.py:162\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    159\u001b[0m }\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "questions = list(qa_df['question'].tolist())\n",
    "expected_answers = list(qa_df['answer'].tolist())\n",
    "predicted_answers = []\n",
    "\n",
    "for index, question in tqdm(enumerate(questions)):\n",
    "  if not question in cache:\n",
    "    cache[question] = app.invoke({'question': question})['generation']\n",
    "\n",
    "  predicted_answers.append(cache[question])\n",
    "\n",
    "  with open(cache_path, 'w') as f:\n",
    "    json.dump(cache, f)\n",
    "\n",
    "cos_score = embeddings_cosine_sim_metric(expected_answers, predicted_answers)\n",
    "bleu_score = bleu_metric(expected_answers, predicted_answers)\n",
    "rogue_1_score = rogue_1_metric(expected_answers, predicted_answers)\n",
    "rogue_l_score = rogue_l_metric(expected_answers, predicted_answers)\n",
    "\n",
    "cos_score, bleu_score, rogue_1_score, rogue_l_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
